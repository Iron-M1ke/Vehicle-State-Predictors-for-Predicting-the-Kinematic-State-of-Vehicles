{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab03419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in c:\\users\\strid\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: fiona>=1.8.19 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from geopandas) (1.9.4.post1)\n",
      "Requirement already satisfied: packaging in c:\\users\\strid\\anaconda3\\lib\\site-packages (from geopandas) (23.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from geopandas) (1.5.3)\n",
      "Requirement already satisfied: pyproj>=3.0.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from geopandas) (3.6.0)\n",
      "Requirement already satisfied: shapely>=1.7.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from geopandas) (2.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from fiona>=1.8.19->geopandas) (22.1.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\strid\\anaconda3\\lib\\site-packages (from fiona>=1.8.19->geopandas) (2023.5.7)\n",
      "Requirement already satisfied: click~=8.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from fiona>=1.8.19->geopandas) (8.0.4)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in c:\\users\\strid\\anaconda3\\lib\\site-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->geopandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->geopandas) (1.24.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\strid\\anaconda3\\lib\\site-packages (from click~=8.0->fiona>=1.8.19->geopandas) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff7ac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly_express in c:\\users\\strid\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from plotly_express) (1.5.3)\n",
      "Requirement already satisfied: plotly>=4.1.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from plotly_express) (5.9.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from plotly_express) (0.13.5)\n",
      "Requirement already satisfied: scipy>=0.18 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from plotly_express) (1.10.1)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from plotly_express) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from plotly_express) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->plotly_express) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->plotly_express) (2022.7)\n",
      "Requirement already satisfied: six in c:\\users\\strid\\anaconda3\\lib\\site-packages (from patsy>=0.5->plotly_express) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from plotly>=4.1.0->plotly_express) (8.2.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->plotly_express) (23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly_express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c5f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in c:\\users\\strid\\anaconda3\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from folium) (0.6.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\strid\\anaconda3\\lib\\site-packages (from folium) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\strid\\anaconda3\\lib\\site-packages (from folium) (2.29.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from jinja2>=2.9->folium) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from requests->folium) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from requests->folium) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from requests->folium) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from requests->folium) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b30321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\strid\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\strid\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e4eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ray\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import plotly_express as px\n",
    "import tensorflow as tf\n",
    "import folium\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd67c24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idtracklet|id1|mmsi1|speed1|course1|heading1|lon1|lat1|ts1|id2|mmsi2|speed2|course2|heading2|lon2|lat2|ts2|id3|mmsi3|speed3|course3|heading3|lon3|lat3|ts3|id4|mmsi4|speed4|course4|heading4|lon4|lat4|ts4|id5|mmsi5|speed5|course5|heading5|lon5|lat5|ts5|route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1|4128997|228005700|6.7|175|511|-4.551695|48.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2|14817869|249104000|8.7|69|69|-4.733975|48.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3|8618319|228017700|14.6|83.7|86|-4.885512|48....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4|16024159|227008170|12.3|125|126|-4.924165|48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5|2144526|228017700|16.5|73.4|73|-4.550415|48....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>796|3554186|227730220|19.1|56.9|511|-4.639665|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>797|1585479|227005550|23.1|68.9|511|-4.547798|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798|2761022|258316000|12.1|338|332|-5.186498|4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>799|5167729|228186700|10.9|104|103|-4.465165|4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800|1922119|227364000|8.8|303.4|308|-4.773423|...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    idtracklet|id1|mmsi1|speed1|course1|heading1|lon1|lat1|ts1|id2|mmsi2|speed2|course2|heading2|lon2|lat2|ts2|id3|mmsi3|speed3|course3|heading3|lon3|lat3|ts3|id4|mmsi4|speed4|course4|heading4|lon4|lat4|ts4|id5|mmsi5|speed5|course5|heading5|lon5|lat5|ts5|route\n",
       "0    1|4128997|228005700|6.7|175|511|-4.551695|48.3...                                                                                                                                                                                                              \n",
       "1    2|14817869|249104000|8.7|69|69|-4.733975|48.30...                                                                                                                                                                                                              \n",
       "2    3|8618319|228017700|14.6|83.7|86|-4.885512|48....                                                                                                                                                                                                              \n",
       "3    4|16024159|227008170|12.3|125|126|-4.924165|48...                                                                                                                                                                                                              \n",
       "4    5|2144526|228017700|16.5|73.4|73|-4.550415|48....                                                                                                                                                                                                              \n",
       "..                                                 ...                                                                                                                                                                                                              \n",
       "795  796|3554186|227730220|19.1|56.9|511|-4.639665|...                                                                                                                                                                                                              \n",
       "796  797|1585479|227005550|23.1|68.9|511|-4.547798|...                                                                                                                                                                                                              \n",
       "797  798|2761022|258316000|12.1|338|332|-5.186498|4...                                                                                                                                                                                                              \n",
       "798  799|5167729|228186700|10.9|104|103|-4.465165|4...                                                                                                                                                                                                              \n",
       "799  800|1922119|227364000|8.8|303.4|308|-4.773423|...                                                                                                                                                                                                              \n",
       "\n",
       "[800 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "db = pd.read_csv(\"tracklets.csv\")\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24040f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idtracklet</th>\n",
       "      <th>id1</th>\n",
       "      <th>mmsi1</th>\n",
       "      <th>speed1</th>\n",
       "      <th>course1</th>\n",
       "      <th>heading1</th>\n",
       "      <th>lon1</th>\n",
       "      <th>lat1</th>\n",
       "      <th>ts1</th>\n",
       "      <th>id2</th>\n",
       "      <th>...</th>\n",
       "      <th>ts4</th>\n",
       "      <th>id5</th>\n",
       "      <th>mmsi5</th>\n",
       "      <th>speed5</th>\n",
       "      <th>course5</th>\n",
       "      <th>heading5</th>\n",
       "      <th>lon5</th>\n",
       "      <th>lat5</th>\n",
       "      <th>ts5</th>\n",
       "      <th>route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4128997</td>\n",
       "      <td>228005700</td>\n",
       "      <td>6.7</td>\n",
       "      <td>175.0</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.551695</td>\n",
       "      <td>48.344520</td>\n",
       "      <td>1447148032</td>\n",
       "      <td>4129047</td>\n",
       "      <td>...</td>\n",
       "      <td>1447148121</td>\n",
       "      <td>4129188</td>\n",
       "      <td>228005700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>325.8</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.551893</td>\n",
       "      <td>48.343353</td>\n",
       "      <td>1447148153</td>\n",
       "      <td>R_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14817869</td>\n",
       "      <td>249104000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69</td>\n",
       "      <td>-4.733975</td>\n",
       "      <td>48.301247</td>\n",
       "      <td>1456438812</td>\n",
       "      <td>14817884</td>\n",
       "      <td>...</td>\n",
       "      <td>1456438842</td>\n",
       "      <td>14817927</td>\n",
       "      <td>249104000</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>69</td>\n",
       "      <td>-4.731818</td>\n",
       "      <td>48.301840</td>\n",
       "      <td>1456438851</td>\n",
       "      <td>R_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8618319</td>\n",
       "      <td>228017700</td>\n",
       "      <td>14.6</td>\n",
       "      <td>83.7</td>\n",
       "      <td>86</td>\n",
       "      <td>-4.885512</td>\n",
       "      <td>48.404390</td>\n",
       "      <td>1451215056</td>\n",
       "      <td>8618323</td>\n",
       "      <td>...</td>\n",
       "      <td>1451215075</td>\n",
       "      <td>8618335</td>\n",
       "      <td>228017700</td>\n",
       "      <td>14.7</td>\n",
       "      <td>84.3</td>\n",
       "      <td>88</td>\n",
       "      <td>-4.882973</td>\n",
       "      <td>48.404560</td>\n",
       "      <td>1451215081</td>\n",
       "      <td>R_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16024159</td>\n",
       "      <td>227008170</td>\n",
       "      <td>12.3</td>\n",
       "      <td>125.0</td>\n",
       "      <td>126</td>\n",
       "      <td>-4.924165</td>\n",
       "      <td>48.405033</td>\n",
       "      <td>1457099514</td>\n",
       "      <td>16024163</td>\n",
       "      <td>...</td>\n",
       "      <td>1457099527</td>\n",
       "      <td>16024186</td>\n",
       "      <td>227008170</td>\n",
       "      <td>12.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>119</td>\n",
       "      <td>-4.922998</td>\n",
       "      <td>48.404335</td>\n",
       "      <td>1457099531</td>\n",
       "      <td>R_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2144526</td>\n",
       "      <td>228017700</td>\n",
       "      <td>16.5</td>\n",
       "      <td>73.4</td>\n",
       "      <td>73</td>\n",
       "      <td>-4.550415</td>\n",
       "      <td>48.351140</td>\n",
       "      <td>1445447976</td>\n",
       "      <td>2144611</td>\n",
       "      <td>...</td>\n",
       "      <td>1445448112</td>\n",
       "      <td>2144738</td>\n",
       "      <td>228017700</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>71</td>\n",
       "      <td>-4.535050</td>\n",
       "      <td>48.354515</td>\n",
       "      <td>1445448122</td>\n",
       "      <td>R_06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>796</td>\n",
       "      <td>3554186</td>\n",
       "      <td>227730220</td>\n",
       "      <td>19.1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.639665</td>\n",
       "      <td>48.315987</td>\n",
       "      <td>1446681907</td>\n",
       "      <td>3554191</td>\n",
       "      <td>...</td>\n",
       "      <td>1446681925</td>\n",
       "      <td>3554214</td>\n",
       "      <td>227730220</td>\n",
       "      <td>19.5</td>\n",
       "      <td>55.2</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.636951</td>\n",
       "      <td>48.317173</td>\n",
       "      <td>1446681932</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>797</td>\n",
       "      <td>1585479</td>\n",
       "      <td>227005550</td>\n",
       "      <td>23.1</td>\n",
       "      <td>68.9</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.547798</td>\n",
       "      <td>48.351620</td>\n",
       "      <td>1444922333</td>\n",
       "      <td>1585481</td>\n",
       "      <td>...</td>\n",
       "      <td>1444922338</td>\n",
       "      <td>1585485</td>\n",
       "      <td>227005550</td>\n",
       "      <td>23.2</td>\n",
       "      <td>69.3</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.547202</td>\n",
       "      <td>48.351772</td>\n",
       "      <td>1444922338</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798</td>\n",
       "      <td>2761022</td>\n",
       "      <td>258316000</td>\n",
       "      <td>12.1</td>\n",
       "      <td>338.0</td>\n",
       "      <td>332</td>\n",
       "      <td>-5.186498</td>\n",
       "      <td>48.084835</td>\n",
       "      <td>1445959658</td>\n",
       "      <td>2761038</td>\n",
       "      <td>...</td>\n",
       "      <td>1445959718</td>\n",
       "      <td>2761117</td>\n",
       "      <td>258316000</td>\n",
       "      <td>12.2</td>\n",
       "      <td>337.0</td>\n",
       "      <td>333</td>\n",
       "      <td>-5.188832</td>\n",
       "      <td>48.088500</td>\n",
       "      <td>1445959727</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>799</td>\n",
       "      <td>5167729</td>\n",
       "      <td>228186700</td>\n",
       "      <td>10.9</td>\n",
       "      <td>104.0</td>\n",
       "      <td>103</td>\n",
       "      <td>-4.465165</td>\n",
       "      <td>48.318333</td>\n",
       "      <td>1448009887</td>\n",
       "      <td>5167735</td>\n",
       "      <td>...</td>\n",
       "      <td>1448009892</td>\n",
       "      <td>5167744</td>\n",
       "      <td>228186700</td>\n",
       "      <td>10.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>101</td>\n",
       "      <td>-4.464665</td>\n",
       "      <td>48.318165</td>\n",
       "      <td>1448009893</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>1922119</td>\n",
       "      <td>227364000</td>\n",
       "      <td>8.8</td>\n",
       "      <td>303.4</td>\n",
       "      <td>308</td>\n",
       "      <td>-4.773423</td>\n",
       "      <td>48.041780</td>\n",
       "      <td>1445255813</td>\n",
       "      <td>1922136</td>\n",
       "      <td>...</td>\n",
       "      <td>1445255852</td>\n",
       "      <td>1922194</td>\n",
       "      <td>227364000</td>\n",
       "      <td>8.6</td>\n",
       "      <td>305.3</td>\n",
       "      <td>312</td>\n",
       "      <td>-4.775925</td>\n",
       "      <td>48.042880</td>\n",
       "      <td>1445255863</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idtracklet       id1      mmsi1  speed1  course1  heading1      lon1  \\\n",
       "0             1   4128997  228005700     6.7    175.0       511 -4.551695   \n",
       "1             2  14817869  249104000     8.7     69.0        69 -4.733975   \n",
       "2             3   8618319  228017700    14.6     83.7        86 -4.885512   \n",
       "3             4  16024159  227008170    12.3    125.0       126 -4.924165   \n",
       "4             5   2144526  228017700    16.5     73.4        73 -4.550415   \n",
       "..          ...       ...        ...     ...      ...       ...       ...   \n",
       "795         796   3554186  227730220    19.1     56.9       511 -4.639665   \n",
       "796         797   1585479  227005550    23.1     68.9       511 -4.547798   \n",
       "797         798   2761022  258316000    12.1    338.0       332 -5.186498   \n",
       "798         799   5167729  228186700    10.9    104.0       103 -4.465165   \n",
       "799         800   1922119  227364000     8.8    303.4       308 -4.773423   \n",
       "\n",
       "          lat1         ts1       id2  ...         ts4       id5      mmsi5  \\\n",
       "0    48.344520  1447148032   4129047  ...  1447148121   4129188  228005700   \n",
       "1    48.301247  1456438812  14817884  ...  1456438842  14817927  249104000   \n",
       "2    48.404390  1451215056   8618323  ...  1451215075   8618335  228017700   \n",
       "3    48.405033  1457099514  16024163  ...  1457099527  16024186  227008170   \n",
       "4    48.351140  1445447976   2144611  ...  1445448112   2144738  228017700   \n",
       "..         ...         ...       ...  ...         ...       ...        ...   \n",
       "795  48.315987  1446681907   3554191  ...  1446681925   3554214  227730220   \n",
       "796  48.351620  1444922333   1585481  ...  1444922338   1585485  227005550   \n",
       "797  48.084835  1445959658   2761038  ...  1445959718   2761117  258316000   \n",
       "798  48.318333  1448009887   5167735  ...  1448009892   5167744  228186700   \n",
       "799  48.041780  1445255813   1922136  ...  1445255852   1922194  227364000   \n",
       "\n",
       "     speed5  course5  heading5      lon5       lat5         ts5  route  \n",
       "0       3.9    325.8       511 -4.551893  48.343353  1447148153   R_07  \n",
       "1       8.5     68.5        69 -4.731818  48.301840  1456438851   R_14  \n",
       "2      14.7     84.3        88 -4.882973  48.404560  1451215081   R_01  \n",
       "3      12.4    130.0       119 -4.922998  48.404335  1457099531   R_11  \n",
       "4      16.0     72.7        71 -4.535050  48.354515  1445448122   R_06  \n",
       "..      ...      ...       ...       ...        ...         ...    ...  \n",
       "795    19.5     55.2       511 -4.636951  48.317173  1446681932    R_0  \n",
       "796    23.2     69.3       511 -4.547202  48.351772  1444922338    R_0  \n",
       "797    12.2    337.0       333 -5.188832  48.088500  1445959727    R_0  \n",
       "798    10.9    105.0       101 -4.464665  48.318165  1448009893    R_0  \n",
       "799     8.6    305.3       312 -4.775925  48.042880  1445255863    R_0  \n",
       "\n",
       "[800 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-import dataset and set delimiter\n",
    "db = pd.read_csv(\"tracklets.csv\", sep=\"|\")\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72be28ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---cc---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 42 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   idtracklet  800 non-null    int64  \n",
      " 1   id1         800 non-null    int64  \n",
      " 2   mmsi1       800 non-null    int64  \n",
      " 3   speed1      800 non-null    float64\n",
      " 4   course1     800 non-null    float64\n",
      " 5   heading1    800 non-null    int64  \n",
      " 6   lon1        800 non-null    float64\n",
      " 7   lat1        800 non-null    float64\n",
      " 8   ts1         800 non-null    int64  \n",
      " 9   id2         800 non-null    int64  \n",
      " 10  mmsi2       800 non-null    int64  \n",
      " 11  speed2      800 non-null    float64\n",
      " 12  course2     800 non-null    float64\n",
      " 13  heading2    800 non-null    int64  \n",
      " 14  lon2        800 non-null    float64\n",
      " 15  lat2        800 non-null    float64\n",
      " 16  ts2         800 non-null    int64  \n",
      " 17  id3         800 non-null    int64  \n",
      " 18  mmsi3       800 non-null    int64  \n",
      " 19  speed3      800 non-null    float64\n",
      " 20  course3     800 non-null    float64\n",
      " 21  heading3    800 non-null    int64  \n",
      " 22  lon3        800 non-null    float64\n",
      " 23  lat3        800 non-null    float64\n",
      " 24  ts3         800 non-null    int64  \n",
      " 25  id4         800 non-null    int64  \n",
      " 26  mmsi4       800 non-null    int64  \n",
      " 27  speed4      800 non-null    float64\n",
      " 28  course4     800 non-null    float64\n",
      " 29  heading4    800 non-null    int64  \n",
      " 30  lon4        800 non-null    float64\n",
      " 31  lat4        800 non-null    float64\n",
      " 32  ts4         800 non-null    int64  \n",
      " 33  id5         800 non-null    int64  \n",
      " 34  mmsi5       800 non-null    int64  \n",
      " 35  speed5      800 non-null    float64\n",
      " 36  course5     800 non-null    float64\n",
      " 37  heading5    800 non-null    int64  \n",
      " 38  lon5        800 non-null    float64\n",
      " 39  lat5        800 non-null    float64\n",
      " 40  ts5         800 non-null    int64  \n",
      " 41  route       800 non-null    object \n",
      "dtypes: float64(20), int64(21), object(1)\n",
      "memory usage: 262.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#examine dataset\n",
    "print(\"---cc---\")\n",
    "print(db.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93722875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracklets Rows:  800\n",
      "Tracklets Columns:  42\n"
     ]
    }
   ],
   "source": [
    "print(\"Tracklets Rows: \", db.shape[0])\n",
    "print(\"Tracklets Columns: \", db.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb126dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#heatmap to detect null values\n",
    "sns.heatmap(db.isnull(), cmap=\"RdBu\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "719f8951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idtracklet</th>\n",
       "      <th>id1</th>\n",
       "      <th>mmsi1</th>\n",
       "      <th>speed1</th>\n",
       "      <th>course1</th>\n",
       "      <th>heading1</th>\n",
       "      <th>lon1</th>\n",
       "      <th>lat1</th>\n",
       "      <th>ts1</th>\n",
       "      <th>id2</th>\n",
       "      <th>...</th>\n",
       "      <th>ts4</th>\n",
       "      <th>id5</th>\n",
       "      <th>mmsi5</th>\n",
       "      <th>speed5</th>\n",
       "      <th>course5</th>\n",
       "      <th>heading5</th>\n",
       "      <th>lon5</th>\n",
       "      <th>lat5</th>\n",
       "      <th>ts5</th>\n",
       "      <th>route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4128997</td>\n",
       "      <td>228005700</td>\n",
       "      <td>6.7</td>\n",
       "      <td>175.0</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.551695</td>\n",
       "      <td>48.344520</td>\n",
       "      <td>1447148032</td>\n",
       "      <td>4129047</td>\n",
       "      <td>...</td>\n",
       "      <td>1447148121</td>\n",
       "      <td>4129188</td>\n",
       "      <td>228005700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>325.8</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.551893</td>\n",
       "      <td>48.343353</td>\n",
       "      <td>1447148153</td>\n",
       "      <td>R_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14817869</td>\n",
       "      <td>249104000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69</td>\n",
       "      <td>-4.733975</td>\n",
       "      <td>48.301247</td>\n",
       "      <td>1456438812</td>\n",
       "      <td>14817884</td>\n",
       "      <td>...</td>\n",
       "      <td>1456438842</td>\n",
       "      <td>14817927</td>\n",
       "      <td>249104000</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>69</td>\n",
       "      <td>-4.731818</td>\n",
       "      <td>48.301840</td>\n",
       "      <td>1456438851</td>\n",
       "      <td>R_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8618319</td>\n",
       "      <td>228017700</td>\n",
       "      <td>14.6</td>\n",
       "      <td>83.7</td>\n",
       "      <td>86</td>\n",
       "      <td>-4.885512</td>\n",
       "      <td>48.404390</td>\n",
       "      <td>1451215056</td>\n",
       "      <td>8618323</td>\n",
       "      <td>...</td>\n",
       "      <td>1451215075</td>\n",
       "      <td>8618335</td>\n",
       "      <td>228017700</td>\n",
       "      <td>14.7</td>\n",
       "      <td>84.3</td>\n",
       "      <td>88</td>\n",
       "      <td>-4.882973</td>\n",
       "      <td>48.404560</td>\n",
       "      <td>1451215081</td>\n",
       "      <td>R_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16024159</td>\n",
       "      <td>227008170</td>\n",
       "      <td>12.3</td>\n",
       "      <td>125.0</td>\n",
       "      <td>126</td>\n",
       "      <td>-4.924165</td>\n",
       "      <td>48.405033</td>\n",
       "      <td>1457099514</td>\n",
       "      <td>16024163</td>\n",
       "      <td>...</td>\n",
       "      <td>1457099527</td>\n",
       "      <td>16024186</td>\n",
       "      <td>227008170</td>\n",
       "      <td>12.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>119</td>\n",
       "      <td>-4.922998</td>\n",
       "      <td>48.404335</td>\n",
       "      <td>1457099531</td>\n",
       "      <td>R_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2144526</td>\n",
       "      <td>228017700</td>\n",
       "      <td>16.5</td>\n",
       "      <td>73.4</td>\n",
       "      <td>73</td>\n",
       "      <td>-4.550415</td>\n",
       "      <td>48.351140</td>\n",
       "      <td>1445447976</td>\n",
       "      <td>2144611</td>\n",
       "      <td>...</td>\n",
       "      <td>1445448112</td>\n",
       "      <td>2144738</td>\n",
       "      <td>228017700</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>71</td>\n",
       "      <td>-4.535050</td>\n",
       "      <td>48.354515</td>\n",
       "      <td>1445448122</td>\n",
       "      <td>R_06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>796</td>\n",
       "      <td>3554186</td>\n",
       "      <td>227730220</td>\n",
       "      <td>19.1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.639665</td>\n",
       "      <td>48.315987</td>\n",
       "      <td>1446681907</td>\n",
       "      <td>3554191</td>\n",
       "      <td>...</td>\n",
       "      <td>1446681925</td>\n",
       "      <td>3554214</td>\n",
       "      <td>227730220</td>\n",
       "      <td>19.5</td>\n",
       "      <td>55.2</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.636951</td>\n",
       "      <td>48.317173</td>\n",
       "      <td>1446681932</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>797</td>\n",
       "      <td>1585479</td>\n",
       "      <td>227005550</td>\n",
       "      <td>23.1</td>\n",
       "      <td>68.9</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.547798</td>\n",
       "      <td>48.351620</td>\n",
       "      <td>1444922333</td>\n",
       "      <td>1585481</td>\n",
       "      <td>...</td>\n",
       "      <td>1444922338</td>\n",
       "      <td>1585485</td>\n",
       "      <td>227005550</td>\n",
       "      <td>23.2</td>\n",
       "      <td>69.3</td>\n",
       "      <td>511</td>\n",
       "      <td>-4.547202</td>\n",
       "      <td>48.351772</td>\n",
       "      <td>1444922338</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798</td>\n",
       "      <td>2761022</td>\n",
       "      <td>258316000</td>\n",
       "      <td>12.1</td>\n",
       "      <td>338.0</td>\n",
       "      <td>332</td>\n",
       "      <td>-5.186498</td>\n",
       "      <td>48.084835</td>\n",
       "      <td>1445959658</td>\n",
       "      <td>2761038</td>\n",
       "      <td>...</td>\n",
       "      <td>1445959718</td>\n",
       "      <td>2761117</td>\n",
       "      <td>258316000</td>\n",
       "      <td>12.2</td>\n",
       "      <td>337.0</td>\n",
       "      <td>333</td>\n",
       "      <td>-5.188832</td>\n",
       "      <td>48.088500</td>\n",
       "      <td>1445959727</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>799</td>\n",
       "      <td>5167729</td>\n",
       "      <td>228186700</td>\n",
       "      <td>10.9</td>\n",
       "      <td>104.0</td>\n",
       "      <td>103</td>\n",
       "      <td>-4.465165</td>\n",
       "      <td>48.318333</td>\n",
       "      <td>1448009887</td>\n",
       "      <td>5167735</td>\n",
       "      <td>...</td>\n",
       "      <td>1448009892</td>\n",
       "      <td>5167744</td>\n",
       "      <td>228186700</td>\n",
       "      <td>10.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>101</td>\n",
       "      <td>-4.464665</td>\n",
       "      <td>48.318165</td>\n",
       "      <td>1448009893</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>1922119</td>\n",
       "      <td>227364000</td>\n",
       "      <td>8.8</td>\n",
       "      <td>303.4</td>\n",
       "      <td>308</td>\n",
       "      <td>-4.773423</td>\n",
       "      <td>48.041780</td>\n",
       "      <td>1445255813</td>\n",
       "      <td>1922136</td>\n",
       "      <td>...</td>\n",
       "      <td>1445255852</td>\n",
       "      <td>1922194</td>\n",
       "      <td>227364000</td>\n",
       "      <td>8.6</td>\n",
       "      <td>305.3</td>\n",
       "      <td>312</td>\n",
       "      <td>-4.775925</td>\n",
       "      <td>48.042880</td>\n",
       "      <td>1445255863</td>\n",
       "      <td>R_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idtracklet       id1      mmsi1  speed1  course1  heading1      lon1  \\\n",
       "0             1   4128997  228005700     6.7    175.0       511 -4.551695   \n",
       "1             2  14817869  249104000     8.7     69.0        69 -4.733975   \n",
       "2             3   8618319  228017700    14.6     83.7        86 -4.885512   \n",
       "3             4  16024159  227008170    12.3    125.0       126 -4.924165   \n",
       "4             5   2144526  228017700    16.5     73.4        73 -4.550415   \n",
       "..          ...       ...        ...     ...      ...       ...       ...   \n",
       "795         796   3554186  227730220    19.1     56.9       511 -4.639665   \n",
       "796         797   1585479  227005550    23.1     68.9       511 -4.547798   \n",
       "797         798   2761022  258316000    12.1    338.0       332 -5.186498   \n",
       "798         799   5167729  228186700    10.9    104.0       103 -4.465165   \n",
       "799         800   1922119  227364000     8.8    303.4       308 -4.773423   \n",
       "\n",
       "          lat1         ts1       id2  ...         ts4       id5      mmsi5  \\\n",
       "0    48.344520  1447148032   4129047  ...  1447148121   4129188  228005700   \n",
       "1    48.301247  1456438812  14817884  ...  1456438842  14817927  249104000   \n",
       "2    48.404390  1451215056   8618323  ...  1451215075   8618335  228017700   \n",
       "3    48.405033  1457099514  16024163  ...  1457099527  16024186  227008170   \n",
       "4    48.351140  1445447976   2144611  ...  1445448112   2144738  228017700   \n",
       "..         ...         ...       ...  ...         ...       ...        ...   \n",
       "795  48.315987  1446681907   3554191  ...  1446681925   3554214  227730220   \n",
       "796  48.351620  1444922333   1585481  ...  1444922338   1585485  227005550   \n",
       "797  48.084835  1445959658   2761038  ...  1445959718   2761117  258316000   \n",
       "798  48.318333  1448009887   5167735  ...  1448009892   5167744  228186700   \n",
       "799  48.041780  1445255813   1922136  ...  1445255852   1922194  227364000   \n",
       "\n",
       "     speed5  course5  heading5      lon5       lat5         ts5  route  \n",
       "0       3.9    325.8       511 -4.551893  48.343353  1447148153   R_07  \n",
       "1       8.5     68.5        69 -4.731818  48.301840  1456438851   R_14  \n",
       "2      14.7     84.3        88 -4.882973  48.404560  1451215081   R_01  \n",
       "3      12.4    130.0       119 -4.922998  48.404335  1457099531   R_11  \n",
       "4      16.0     72.7        71 -4.535050  48.354515  1445448122   R_06  \n",
       "..      ...      ...       ...       ...        ...         ...    ...  \n",
       "795    19.5     55.2       511 -4.636951  48.317173  1446681932    R_0  \n",
       "796    23.2     69.3       511 -4.547202  48.351772  1444922338    R_0  \n",
       "797    12.2    337.0       333 -5.188832  48.088500  1445959727    R_0  \n",
       "798    10.9    105.0       101 -4.464665  48.318165  1448009893    R_0  \n",
       "799     8.6    305.3       312 -4.775925  48.042880  1445255863    R_0  \n",
       "\n",
       "[800 rows x 42 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop potential na values\n",
    "db.dropna(inplace=True)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49e6d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#heatmap to detect null values\n",
    "sns.heatmap(db.isnull(), cmap=\"RdBu\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32320fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only needed if you need to read the UNIX timestamps\n",
    "\n",
    "#process timestamps to human readable format\n",
    "#db['ts1'] = pd.to_datetime(db['ts1'], unit='s')\n",
    "#db['ts2'] = pd.to_datetime(db['ts2'], unit='s')\n",
    "#db['ts3'] = pd.to_datetime(db['ts3'], unit='s')\n",
    "#db['ts4'] = pd.to_datetime(db['ts4'], unit='s')\n",
    "#db['ts5'] = pd.to_datetime(db['ts5'], unit='s')\n",
    "#db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be35148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\strid\\AppData\\Local\\Temp\\ipykernel_11736\\1278685546.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  cm = db.corr()\n"
     ]
    }
   ],
   "source": [
    "#introduce a correlation matrix\n",
    "cm = db.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8edcd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and target selection\n",
    "features = ['speed1', 'course1', 'heading1', 'ts1', 'speed2', 'course2', 'heading2', 'ts2', 'speed3', 'course3', 'heading3', 'ts3', 'speed4', 'course4', 'heading4', 'ts4', 'speed5', 'course5', 'heading5', 'ts5']  \n",
    "targets = ['lon1', 'lat1']  \n",
    "\n",
    "x = db[features]\n",
    "y = db[targets]\n",
    "\n",
    "original_lon1 = db[\"lon1\"]\n",
    "original_lat1 = db[\"lat1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682461b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed1</th>\n",
       "      <th>course1</th>\n",
       "      <th>heading1</th>\n",
       "      <th>ts1</th>\n",
       "      <th>speed2</th>\n",
       "      <th>course2</th>\n",
       "      <th>heading2</th>\n",
       "      <th>ts2</th>\n",
       "      <th>speed3</th>\n",
       "      <th>course3</th>\n",
       "      <th>heading3</th>\n",
       "      <th>ts3</th>\n",
       "      <th>speed4</th>\n",
       "      <th>course4</th>\n",
       "      <th>heading4</th>\n",
       "      <th>ts4</th>\n",
       "      <th>speed5</th>\n",
       "      <th>course5</th>\n",
       "      <th>heading5</th>\n",
       "      <th>ts5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.7</td>\n",
       "      <td>175.0</td>\n",
       "      <td>511</td>\n",
       "      <td>1447148032</td>\n",
       "      <td>6.9</td>\n",
       "      <td>175.5</td>\n",
       "      <td>511</td>\n",
       "      <td>1447148061</td>\n",
       "      <td>2.8</td>\n",
       "      <td>215.6</td>\n",
       "      <td>511</td>\n",
       "      <td>1447148092</td>\n",
       "      <td>2.1</td>\n",
       "      <td>337.5</td>\n",
       "      <td>511</td>\n",
       "      <td>1447148121</td>\n",
       "      <td>3.9</td>\n",
       "      <td>325.8</td>\n",
       "      <td>511</td>\n",
       "      <td>1447148153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.7</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1456438812</td>\n",
       "      <td>8.5</td>\n",
       "      <td>69.1</td>\n",
       "      <td>68</td>\n",
       "      <td>1456438821</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.3</td>\n",
       "      <td>69</td>\n",
       "      <td>1456438832</td>\n",
       "      <td>8.6</td>\n",
       "      <td>67.9</td>\n",
       "      <td>69</td>\n",
       "      <td>1456438842</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>69</td>\n",
       "      <td>1456438851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.6</td>\n",
       "      <td>83.7</td>\n",
       "      <td>86</td>\n",
       "      <td>1451215056</td>\n",
       "      <td>14.7</td>\n",
       "      <td>83.7</td>\n",
       "      <td>86</td>\n",
       "      <td>1451215063</td>\n",
       "      <td>14.7</td>\n",
       "      <td>83.8</td>\n",
       "      <td>86</td>\n",
       "      <td>1451215069</td>\n",
       "      <td>14.6</td>\n",
       "      <td>84.1</td>\n",
       "      <td>87</td>\n",
       "      <td>1451215075</td>\n",
       "      <td>14.7</td>\n",
       "      <td>84.3</td>\n",
       "      <td>88</td>\n",
       "      <td>1451215081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.3</td>\n",
       "      <td>125.0</td>\n",
       "      <td>126</td>\n",
       "      <td>1457099514</td>\n",
       "      <td>12.6</td>\n",
       "      <td>130.0</td>\n",
       "      <td>125</td>\n",
       "      <td>1457099516</td>\n",
       "      <td>12.8</td>\n",
       "      <td>132.0</td>\n",
       "      <td>124</td>\n",
       "      <td>1457099521</td>\n",
       "      <td>12.5</td>\n",
       "      <td>131.0</td>\n",
       "      <td>121</td>\n",
       "      <td>1457099527</td>\n",
       "      <td>12.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1457099531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.5</td>\n",
       "      <td>73.4</td>\n",
       "      <td>73</td>\n",
       "      <td>1445447976</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>69</td>\n",
       "      <td>1445448036</td>\n",
       "      <td>15.8</td>\n",
       "      <td>70.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1445448052</td>\n",
       "      <td>16.1</td>\n",
       "      <td>72.8</td>\n",
       "      <td>73</td>\n",
       "      <td>1445448112</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>71</td>\n",
       "      <td>1445448122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>19.1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>511</td>\n",
       "      <td>1446681907</td>\n",
       "      <td>19.5</td>\n",
       "      <td>57.7</td>\n",
       "      <td>511</td>\n",
       "      <td>1446681913</td>\n",
       "      <td>19.9</td>\n",
       "      <td>59.2</td>\n",
       "      <td>511</td>\n",
       "      <td>1446681919</td>\n",
       "      <td>19.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>511</td>\n",
       "      <td>1446681925</td>\n",
       "      <td>19.5</td>\n",
       "      <td>55.2</td>\n",
       "      <td>511</td>\n",
       "      <td>1446681932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>23.1</td>\n",
       "      <td>68.9</td>\n",
       "      <td>511</td>\n",
       "      <td>1444922333</td>\n",
       "      <td>23.2</td>\n",
       "      <td>69.1</td>\n",
       "      <td>511</td>\n",
       "      <td>1444922335</td>\n",
       "      <td>23.2</td>\n",
       "      <td>69.3</td>\n",
       "      <td>511</td>\n",
       "      <td>1444922337</td>\n",
       "      <td>23.2</td>\n",
       "      <td>69.7</td>\n",
       "      <td>511</td>\n",
       "      <td>1444922338</td>\n",
       "      <td>23.2</td>\n",
       "      <td>69.3</td>\n",
       "      <td>511</td>\n",
       "      <td>1444922338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>12.1</td>\n",
       "      <td>338.0</td>\n",
       "      <td>332</td>\n",
       "      <td>1445959658</td>\n",
       "      <td>12.1</td>\n",
       "      <td>338.0</td>\n",
       "      <td>332</td>\n",
       "      <td>1445959667</td>\n",
       "      <td>12.2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>332</td>\n",
       "      <td>1445959677</td>\n",
       "      <td>12.2</td>\n",
       "      <td>337.0</td>\n",
       "      <td>333</td>\n",
       "      <td>1445959718</td>\n",
       "      <td>12.2</td>\n",
       "      <td>337.0</td>\n",
       "      <td>333</td>\n",
       "      <td>1445959727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>10.9</td>\n",
       "      <td>104.0</td>\n",
       "      <td>103</td>\n",
       "      <td>1448009887</td>\n",
       "      <td>10.9</td>\n",
       "      <td>104.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1448009889</td>\n",
       "      <td>10.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1448009890</td>\n",
       "      <td>10.9</td>\n",
       "      <td>107.0</td>\n",
       "      <td>101</td>\n",
       "      <td>1448009892</td>\n",
       "      <td>10.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>101</td>\n",
       "      <td>1448009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>8.8</td>\n",
       "      <td>303.4</td>\n",
       "      <td>308</td>\n",
       "      <td>1445255813</td>\n",
       "      <td>8.8</td>\n",
       "      <td>302.6</td>\n",
       "      <td>309</td>\n",
       "      <td>1445255823</td>\n",
       "      <td>8.7</td>\n",
       "      <td>303.0</td>\n",
       "      <td>308</td>\n",
       "      <td>1445255832</td>\n",
       "      <td>8.7</td>\n",
       "      <td>302.0</td>\n",
       "      <td>311</td>\n",
       "      <td>1445255852</td>\n",
       "      <td>8.6</td>\n",
       "      <td>305.3</td>\n",
       "      <td>312</td>\n",
       "      <td>1445255863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speed1  course1  heading1         ts1  speed2  course2  heading2  \\\n",
       "0       6.7    175.0       511  1447148032     6.9    175.5       511   \n",
       "1       8.7     69.0        69  1456438812     8.5     69.1        68   \n",
       "2      14.6     83.7        86  1451215056    14.7     83.7        86   \n",
       "3      12.3    125.0       126  1457099514    12.6    130.0       125   \n",
       "4      16.5     73.4        73  1445447976    16.0     70.3        69   \n",
       "..      ...      ...       ...         ...     ...      ...       ...   \n",
       "795    19.1     56.9       511  1446681907    19.5     57.7       511   \n",
       "796    23.1     68.9       511  1444922333    23.2     69.1       511   \n",
       "797    12.1    338.0       332  1445959658    12.1    338.0       332   \n",
       "798    10.9    104.0       103  1448009887    10.9    104.0       102   \n",
       "799     8.8    303.4       308  1445255813     8.8    302.6       309   \n",
       "\n",
       "            ts2  speed3  course3  heading3         ts3  speed4  course4  \\\n",
       "0    1447148061     2.8    215.6       511  1447148092     2.1    337.5   \n",
       "1    1456438821     8.5     68.3        69  1456438832     8.6     67.9   \n",
       "2    1451215063    14.7     83.8        86  1451215069    14.6     84.1   \n",
       "3    1457099516    12.8    132.0       124  1457099521    12.5    131.0   \n",
       "4    1445448036    15.8     70.5        71  1445448052    16.1     72.8   \n",
       "..          ...     ...      ...       ...         ...     ...      ...   \n",
       "795  1446681913    19.9     59.2       511  1446681919    19.0     55.4   \n",
       "796  1444922335    23.2     69.3       511  1444922337    23.2     69.7   \n",
       "797  1445959667    12.2    338.0       332  1445959677    12.2    337.0   \n",
       "798  1448009889    10.9    105.0       102  1448009890    10.9    107.0   \n",
       "799  1445255823     8.7    303.0       308  1445255832     8.7    302.0   \n",
       "\n",
       "     heading4         ts4  speed5  course5  heading5         ts5  \n",
       "0         511  1447148121     3.9    325.8       511  1447148153  \n",
       "1          69  1456438842     8.5     68.5        69  1456438851  \n",
       "2          87  1451215075    14.7     84.3        88  1451215081  \n",
       "3         121  1457099527    12.4    130.0       119  1457099531  \n",
       "4          73  1445448112    16.0     72.7        71  1445448122  \n",
       "..        ...         ...     ...      ...       ...         ...  \n",
       "795       511  1446681925    19.5     55.2       511  1446681932  \n",
       "796       511  1444922338    23.2     69.3       511  1444922338  \n",
       "797       333  1445959718    12.2    337.0       333  1445959727  \n",
       "798       101  1448009892    10.9    105.0       101  1448009893  \n",
       "799       311  1445255852     8.6    305.3       312  1445255863  \n",
       "\n",
       "[800 rows x 20 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine x then y\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2294f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon1</th>\n",
       "      <th>lat1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.551695</td>\n",
       "      <td>48.344520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.733975</td>\n",
       "      <td>48.301247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.885512</td>\n",
       "      <td>48.404390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.924165</td>\n",
       "      <td>48.405033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.550415</td>\n",
       "      <td>48.351140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>-4.639665</td>\n",
       "      <td>48.315987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>-4.547798</td>\n",
       "      <td>48.351620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>-5.186498</td>\n",
       "      <td>48.084835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>-4.465165</td>\n",
       "      <td>48.318333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>-4.773423</td>\n",
       "      <td>48.041780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lon1       lat1\n",
       "0   -4.551695  48.344520\n",
       "1   -4.733975  48.301247\n",
       "2   -4.885512  48.404390\n",
       "3   -4.924165  48.405033\n",
       "4   -4.550415  48.351140\n",
       "..        ...        ...\n",
       "795 -4.639665  48.315987\n",
       "796 -4.547798  48.351620\n",
       "797 -5.186498  48.084835\n",
       "798 -4.465165  48.318333\n",
       "799 -4.773423  48.041780\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cf2ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a1b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95446dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 8s 29ms/step - loss: 1172.0048 - val_loss: 1166.6090\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1108.3752 - val_loss: 540.4412\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 360.0225 - val_loss: 286.3907\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 246.8017 - val_loss: 230.9465\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 178.2530 - val_loss: 162.8701\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 134.1982 - val_loss: 123.3490\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 100.9307 - val_loss: 93.7211\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 77.5676 - val_loss: 75.5071\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 59.7787 - val_loss: 61.7391\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 43.9725 - val_loss: 43.1338\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 33.8346 - val_loss: 37.4870\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 24.4284 - val_loss: 25.4565\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 19.3712 - val_loss: 21.2973\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 14.2414 - val_loss: 13.5097\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 10.1029 - val_loss: 11.0073\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 7.1228 - val_loss: 7.6419\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.8988 - val_loss: 5.8355\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 3.5346 - val_loss: 4.2873\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 2.5662 - val_loss: 2.9721\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.9137 - val_loss: 2.3311\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.4922 - val_loss: 2.7510\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.1813 - val_loss: 2.0189\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.9966 - val_loss: 1.9885\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.8495 - val_loss: 1.4996\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.8220 - val_loss: 1.7748\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7213 - val_loss: 1.4877\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8158 - val_loss: 1.3239\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.7342 - val_loss: 1.3560\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6466 - val_loss: 1.6143\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.5431 - val_loss: 1.1441\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.5184 - val_loss: 1.6997\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7732 - val_loss: 1.4392\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4879 - val_loss: 1.1922\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3777 - val_loss: 1.1417\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3678 - val_loss: 1.0886\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3768 - val_loss: 1.1547\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4300 - val_loss: 1.0580\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3562 - val_loss: 1.1184\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3691 - val_loss: 1.3898\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3681 - val_loss: 1.3430\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4123 - val_loss: 1.6840\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3404 - val_loss: 1.3927\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3596 - val_loss: 1.0072\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3397 - val_loss: 1.5554\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.1328 - val_loss: 3.4446\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.3646 - val_loss: 1.5791\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.8926 - val_loss: 1.1419\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5585 - val_loss: 0.9172\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2656 - val_loss: 1.1822\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2099 - val_loss: 0.8326\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2472 - val_loss: 1.0199\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2160 - val_loss: 0.8251\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1701 - val_loss: 0.8852\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.2267 - val_loss: 0.8782\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2196 - val_loss: 1.0306\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1690 - val_loss: 0.8182\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2335 - val_loss: 1.0570\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2255 - val_loss: 1.3454\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2446 - val_loss: 0.8324\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2422 - val_loss: 1.0508\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1632 - val_loss: 0.9034\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1718 - val_loss: 0.8647\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1678 - val_loss: 1.2620\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2167 - val_loss: 0.8468\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1445 - val_loss: 0.7992\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.1609 - val_loss: 1.3257\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.1749 - val_loss: 0.9970\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.1405 - val_loss: 0.7610\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.1503 - val_loss: 0.9760\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.2169 - val_loss: 0.8838\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.3014 - val_loss: 0.9585\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.3043 - val_loss: 1.0406\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.2210 - val_loss: 1.1505\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.2681 - val_loss: 1.2538\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2615 - val_loss: 0.9233\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2534 - val_loss: 1.0432\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2733 - val_loss: 0.9750\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4065 - val_loss: 1.1489\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2742 - val_loss: 0.7192\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3977 - val_loss: 1.1110\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4939 - val_loss: 1.2409\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3849 - val_loss: 0.8181\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4455 - val_loss: 1.0265\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2282 - val_loss: 0.8795\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1875 - val_loss: 1.0472\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2322 - val_loss: 1.0164\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2353 - val_loss: 0.9434\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1897 - val_loss: 0.7905\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.2494 - val_loss: 1.3967\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1677 - val_loss: 1.1033\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2571 - val_loss: 1.2212\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1832 - val_loss: 0.9920\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3161 - val_loss: 1.4938\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2983 - val_loss: 0.8978\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1830 - val_loss: 0.7884\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1584 - val_loss: 1.1180\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1341 - val_loss: 0.7273\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1150 - val_loss: 0.7088\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1181 - val_loss: 0.7832\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1475 - val_loss: 0.9537\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1667 - val_loss: 1.1664\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3127 - val_loss: 0.8804\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1759 - val_loss: 1.1340\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6192 - val_loss: 1.5474\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 1.0815 - val_loss: 1.6555\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4046 - val_loss: 1.1132\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3201 - val_loss: 0.9795\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5340 - val_loss: 2.5292\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5454 - val_loss: 0.9350\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2148 - val_loss: 0.7349\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2775 - val_loss: 1.0022\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2478 - val_loss: 0.7172\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.4135 - val_loss: 0.7926\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.1884 - val_loss: 0.8648\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.4147 - val_loss: 0.9210\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.3906 - val_loss: 1.5784\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6883 - val_loss: 1.5492\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6524 - val_loss: 1.2706\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5965 - val_loss: 0.8428\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.3114 - val_loss: 0.6862\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2131 - val_loss: 0.7996\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1791 - val_loss: 0.7308\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1520 - val_loss: 0.7642\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1454 - val_loss: 0.7097\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2117 - val_loss: 0.8401\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4806 - val_loss: 0.6631\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1928 - val_loss: 0.7949\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1882 - val_loss: 0.6989\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1701 - val_loss: 1.0522\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2197 - val_loss: 0.6575\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2151 - val_loss: 1.1158\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2220 - val_loss: 0.5590\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1639 - val_loss: 0.9036\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1724 - val_loss: 1.0771\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2381 - val_loss: 0.8190\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.1741 - val_loss: 0.7432\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2723 - val_loss: 0.6433\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1291 - val_loss: 0.6702\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1127 - val_loss: 0.7634\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.2088 - val_loss: 0.6080\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.1352 - val_loss: 0.8614\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.1339 - val_loss: 0.6488\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.1084 - val_loss: 0.5765\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.1311 - val_loss: 0.8038\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.1247 - val_loss: 0.6038\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1771 - val_loss: 0.7234\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1607 - val_loss: 0.6613\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2346 - val_loss: 0.6658\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2054 - val_loss: 0.6981\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4404 - val_loss: 0.7113\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2485 - val_loss: 0.9609\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3886 - val_loss: 0.8716\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6707 - val_loss: 1.0025\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3490 - val_loss: 0.6395\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2693 - val_loss: 0.7972\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3759 - val_loss: 0.6560\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.1745 - val_loss: 0.6799\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4094 - val_loss: 0.9003\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3088 - val_loss: 0.8177\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.1719 - val_loss: 1.4551\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3394 - val_loss: 0.7830\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2385 - val_loss: 0.5542\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1813 - val_loss: 0.5225\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1298 - val_loss: 0.7436\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2718 - val_loss: 0.6424\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1543 - val_loss: 0.4923\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0923 - val_loss: 0.5138\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0876 - val_loss: 0.5729\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0615 - val_loss: 0.5974\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1069 - val_loss: 0.5299\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1576 - val_loss: 0.8510\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1515 - val_loss: 0.6612\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1249 - val_loss: 0.4875\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1463 - val_loss: 0.6794\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1621 - val_loss: 0.9053\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2530 - val_loss: 0.8803\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5540 - val_loss: 1.8374\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.7784 - val_loss: 1.0736\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.0509 - val_loss: 0.7565\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.3326 - val_loss: 1.3619\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8959 - val_loss: 1.1284\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4473 - val_loss: 0.8290\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2753 - val_loss: 0.5390\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2115 - val_loss: 1.5334\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6049 - val_loss: 0.6140\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5052 - val_loss: 0.8665\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2818 - val_loss: 0.7604\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2187 - val_loss: 0.7601\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1111 - val_loss: 0.5165\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0919 - val_loss: 0.4047\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0685 - val_loss: 0.5004\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1016 - val_loss: 0.6335\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0889 - val_loss: 0.4304\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0846 - val_loss: 0.5345\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0819 - val_loss: 0.5072\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0690 - val_loss: 0.5290\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0796 - val_loss: 0.5644\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0631 - val_loss: 0.4308\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0622 - val_loss: 0.4737\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0617 - val_loss: 0.5941\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0844 - val_loss: 0.4945\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1733 - val_loss: 0.4004\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1047 - val_loss: 0.5877\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0896 - val_loss: 0.4056\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.4359\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0571 - val_loss: 0.3868\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0812 - val_loss: 0.6783\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1656 - val_loss: 0.7146\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1353 - val_loss: 0.5772\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1326 - val_loss: 0.4535\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2368 - val_loss: 1.0172\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4744 - val_loss: 1.2545\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5253 - val_loss: 1.4606\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 1.7342 - val_loss: 0.7662\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4386 - val_loss: 0.6625\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4572 - val_loss: 1.4029\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3089 - val_loss: 0.7266\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1570 - val_loss: 0.9417\n",
      "Epoch 219/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2576 - val_loss: 0.4733\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1424 - val_loss: 0.4699\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1331 - val_loss: 0.4294\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0795 - val_loss: 0.4104\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0785 - val_loss: 0.4247\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0901 - val_loss: 0.5413\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0754 - val_loss: 0.4166\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0658 - val_loss: 0.4206\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0878 - val_loss: 0.4886\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0717 - val_loss: 0.4825\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0652 - val_loss: 0.3919\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0548 - val_loss: 0.4387\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0774 - val_loss: 0.4631\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0504 - val_loss: 0.3989\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0971 - val_loss: 0.5355\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1777 - val_loss: 0.6850\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1496 - val_loss: 0.6211\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.1563 - val_loss: 0.7640\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1277 - val_loss: 0.5533\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1424 - val_loss: 0.5533\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2543 - val_loss: 1.5738\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.7504 - val_loss: 1.2174\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6112 - val_loss: 0.8489\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3925 - val_loss: 1.1158\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3468 - val_loss: 0.5585\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1656 - val_loss: 0.4620\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1026 - val_loss: 0.4404\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0742 - val_loss: 0.3862\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0720 - val_loss: 0.4239\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0768 - val_loss: 0.3764\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0564 - val_loss: 0.3922\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0570 - val_loss: 0.3268\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0517 - val_loss: 0.3692\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0693 - val_loss: 0.3683\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0904 - val_loss: 0.4319\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0591 - val_loss: 0.3539\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1167 - val_loss: 0.3354\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0725 - val_loss: 0.3321\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0503 - val_loss: 0.4266\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0603 - val_loss: 0.4013\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0610 - val_loss: 0.4267\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1512 - val_loss: 0.3374\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0842 - val_loss: 0.3591\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0740 - val_loss: 0.4004\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0543 - val_loss: 0.3233\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0614 - val_loss: 0.4976\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1353 - val_loss: 0.4433\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2018 - val_loss: 0.5511\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2515 - val_loss: 0.5254\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4866 - val_loss: 2.8488\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.8368 - val_loss: 0.4916\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3018 - val_loss: 0.4862\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2444 - val_loss: 0.4333\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1112 - val_loss: 0.5708\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1206 - val_loss: 0.4793\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0972 - val_loss: 0.3636\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0631 - val_loss: 0.3584\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0809 - val_loss: 0.4588\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0775 - val_loss: 0.3579\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1241 - val_loss: 0.4237\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0748 - val_loss: 0.3695\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0552 - val_loss: 0.4694\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1335 - val_loss: 0.4087\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0684 - val_loss: 0.4071\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0638 - val_loss: 0.3681\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0665 - val_loss: 0.3154\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0830 - val_loss: 0.3234\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0630 - val_loss: 0.3073\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0661 - val_loss: 0.3872\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0600 - val_loss: 0.3509\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2196 - val_loss: 0.7731\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1649 - val_loss: 0.5165\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1561 - val_loss: 0.3599\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1289 - val_loss: 0.5589\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2067 - val_loss: 0.3318\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0830 - val_loss: 0.4043\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0503 - val_loss: 0.2860\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0798 - val_loss: 0.4221\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0713 - val_loss: 0.3432\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0755 - val_loss: 0.5345\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2160 - val_loss: 0.7326\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1899 - val_loss: 0.4189\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4033 - val_loss: 2.5495\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 2.8081 - val_loss: 1.0237\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6214 - val_loss: 1.6960\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4165 - val_loss: 1.1826\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.6421 - val_loss: 0.8073\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.4132 - val_loss: 0.8539\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2097 - val_loss: 0.4299\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2013 - val_loss: 0.3930\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1428 - val_loss: 0.3214\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0937 - val_loss: 0.3518\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0926 - val_loss: 0.2885\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0561 - val_loss: 0.2820\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0492 - val_loss: 0.3133\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0547 - val_loss: 0.2701\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0524 - val_loss: 0.2824\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0713 - val_loss: 0.2880\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0654 - val_loss: 0.2853\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0493 - val_loss: 0.2852\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0468 - val_loss: 0.2764\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0528 - val_loss: 0.2649\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0485 - val_loss: 0.6135\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1353 - val_loss: 0.3012\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1082 - val_loss: 0.2978\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0643 - val_loss: 0.2839\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0609 - val_loss: 0.3196\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0502 - val_loss: 0.3223\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.1049 - val_loss: 0.3038\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0803 - val_loss: 0.2490\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0423 - val_loss: 0.2915\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0860 - val_loss: 0.3470\n",
      "Epoch 331/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1658 - val_loss: 0.9302\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2759 - val_loss: 0.4744\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2365 - val_loss: 0.6017\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3571 - val_loss: 0.4674\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1873 - val_loss: 0.4021\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2872 - val_loss: 0.4517\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1339 - val_loss: 0.4128\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1320 - val_loss: 0.5712\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2326 - val_loss: 0.6268\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2243 - val_loss: 0.4098\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1218 - val_loss: 0.3655\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2694 - val_loss: 0.5737\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1477 - val_loss: 0.4083\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2507 - val_loss: 0.3311\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.1572 - val_loss: 0.3713\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0992 - val_loss: 0.2806\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1228 - val_loss: 0.3211\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0648 - val_loss: 0.3102\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0449 - val_loss: 0.3478\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0547 - val_loss: 0.2185\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0459 - val_loss: 0.2503\n",
      "Epoch 352/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0349 - val_loss: 0.2004\n",
      "Epoch 353/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0443 - val_loss: 0.2143\n",
      "Epoch 354/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0430 - val_loss: 0.2338\n",
      "Epoch 355/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0620 - val_loss: 0.2301\n",
      "Epoch 356/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0582 - val_loss: 0.2132\n",
      "Epoch 357/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0471 - val_loss: 0.2092\n",
      "Epoch 358/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0637 - val_loss: 0.2129\n",
      "Epoch 359/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0725 - val_loss: 0.2337\n",
      "Epoch 360/1000\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0712 - val_loss: 0.2556\n",
      "Epoch 361/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0618 - val_loss: 0.2541\n",
      "Epoch 362/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0890 - val_loss: 0.4357\n",
      "Epoch 363/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1022 - val_loss: 0.2204\n",
      "Epoch 364/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0879 - val_loss: 0.2554\n",
      "Epoch 365/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1100 - val_loss: 0.2684\n",
      "Epoch 366/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1281 - val_loss: 0.2570\n",
      "Epoch 367/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0571 - val_loss: 0.2336\n",
      "Epoch 368/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0536 - val_loss: 0.2450\n",
      "Epoch 369/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0554 - val_loss: 0.3028\n",
      "Epoch 370/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0550 - val_loss: 0.2435\n",
      "Epoch 371/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0857 - val_loss: 0.2186\n",
      "Epoch 372/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1237 - val_loss: 0.4243\n",
      "Epoch 373/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1777 - val_loss: 0.3133\n",
      "Epoch 374/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1595 - val_loss: 0.3210\n",
      "Epoch 375/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3046 - val_loss: 0.5696\n",
      "Epoch 376/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1845 - val_loss: 0.2907\n",
      "Epoch 377/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1145 - val_loss: 0.2434\n",
      "Epoch 378/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1202 - val_loss: 0.2961\n",
      "Epoch 379/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0946 - val_loss: 0.2373\n",
      "Epoch 380/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0933 - val_loss: 0.3237\n",
      "Epoch 381/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2308 - val_loss: 0.2820\n",
      "Epoch 382/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0854 - val_loss: 0.2126\n",
      "Epoch 383/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0580 - val_loss: 0.1685\n",
      "Epoch 384/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0469 - val_loss: 0.1852\n",
      "Epoch 385/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0551 - val_loss: 0.2195\n",
      "Epoch 386/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0765 - val_loss: 0.2341\n",
      "Epoch 387/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1282 - val_loss: 0.3785\n",
      "Epoch 388/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2444 - val_loss: 0.5722\n",
      "Epoch 389/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3078 - val_loss: 0.4281\n",
      "Epoch 390/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3736 - val_loss: 0.4178\n",
      "Epoch 391/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1725 - val_loss: 0.3539\n",
      "Epoch 392/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1891 - val_loss: 0.4048\n",
      "Epoch 393/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2596 - val_loss: 1.0847\n",
      "Epoch 394/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4558 - val_loss: 0.7527\n",
      "Epoch 395/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6360 - val_loss: 0.2083\n",
      "Epoch 396/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.1414 - val_loss: 0.4485\n",
      "Epoch 397/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0914 - val_loss: 0.1682\n",
      "Epoch 398/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1960 - val_loss: 0.4880\n",
      "Epoch 399/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1775 - val_loss: 0.6077\n",
      "Epoch 400/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2215 - val_loss: 0.3401\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0982 - val_loss: 0.2782\n",
      "Epoch 402/1000\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.1238 - val_loss: 0.2800\n",
      "Epoch 403/1000\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0972 - val_loss: 0.5442\n",
      "Epoch 404/1000\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0931 - val_loss: 0.1614\n",
      "Epoch 405/1000\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0511 - val_loss: 0.1726\n",
      "Epoch 406/1000\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0472 - val_loss: 0.2600\n",
      "Epoch 407/1000\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0495 - val_loss: 0.1877\n",
      "Epoch 408/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0397 - val_loss: 0.1504\n",
      "Epoch 409/1000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.1422\n",
      "Epoch 410/1000\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0442 - val_loss: 0.1634\n",
      "Epoch 411/1000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0503 - val_loss: 0.1561\n",
      "Epoch 412/1000\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0554 - val_loss: 0.1550\n",
      "Epoch 413/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0530 - val_loss: 0.1334\n",
      "Epoch 414/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0539 - val_loss: 0.1483\n",
      "Epoch 415/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0586 - val_loss: 0.1600\n",
      "Epoch 416/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0429 - val_loss: 0.2360\n",
      "Epoch 417/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0564 - val_loss: 0.2081\n",
      "Epoch 418/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0527 - val_loss: 0.1451\n",
      "Epoch 419/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0507 - val_loss: 0.1671\n",
      "Epoch 420/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0508 - val_loss: 0.2014\n",
      "Epoch 421/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0939 - val_loss: 0.2537\n",
      "Epoch 422/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1325 - val_loss: 0.2819\n",
      "Epoch 423/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1919 - val_loss: 0.2791\n",
      "Epoch 424/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0815 - val_loss: 0.1670\n",
      "Epoch 425/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.1596\n",
      "Epoch 426/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0465 - val_loss: 0.1393\n",
      "Epoch 427/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0370 - val_loss: 0.1413\n",
      "Epoch 428/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0454 - val_loss: 0.1375\n",
      "Epoch 429/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0546 - val_loss: 0.2487\n",
      "Epoch 430/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0606 - val_loss: 0.1421\n",
      "Epoch 431/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0617 - val_loss: 0.3061\n",
      "Epoch 432/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1010 - val_loss: 0.1793\n",
      "Epoch 433/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.1909\n",
      "Epoch 434/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0815 - val_loss: 0.3122\n",
      "Epoch 435/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1545 - val_loss: 0.2547\n",
      "Epoch 436/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1373 - val_loss: 0.4079\n",
      "Epoch 437/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1375 - val_loss: 0.2120\n",
      "Epoch 438/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0778 - val_loss: 0.1199\n",
      "Epoch 439/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1147 - val_loss: 0.2767\n",
      "Epoch 440/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0871 - val_loss: 0.2884\n",
      "Epoch 441/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0818 - val_loss: 0.1625\n",
      "Epoch 442/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.1750\n",
      "Epoch 443/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0542 - val_loss: 0.1563\n",
      "Epoch 444/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0471 - val_loss: 0.1832\n",
      "Epoch 445/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0643 - val_loss: 0.1420\n",
      "Epoch 446/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.1865\n",
      "Epoch 447/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0605 - val_loss: 0.1624\n",
      "Epoch 448/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0838 - val_loss: 0.3008\n",
      "Epoch 449/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0989 - val_loss: 0.2526\n",
      "Epoch 450/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1168 - val_loss: 0.6104\n",
      "Epoch 451/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1290 - val_loss: 0.1504\n",
      "Epoch 452/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0665 - val_loss: 0.1656\n",
      "Epoch 453/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0863 - val_loss: 0.1344\n",
      "Epoch 454/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0625 - val_loss: 0.1282\n",
      "Epoch 455/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0747 - val_loss: 0.1704\n",
      "Epoch 456/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0917 - val_loss: 0.1461\n",
      "Epoch 457/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1380 - val_loss: 0.1076\n",
      "Epoch 458/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0931 - val_loss: 0.2316\n",
      "Epoch 459/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0838 - val_loss: 0.2599\n",
      "Epoch 460/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1392 - val_loss: 0.2829\n",
      "Epoch 461/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1297 - val_loss: 0.2281\n",
      "Epoch 462/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1093 - val_loss: 0.4236\n",
      "Epoch 463/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1947 - val_loss: 0.2045\n",
      "Epoch 464/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1177 - val_loss: 0.1733\n",
      "Epoch 465/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0601 - val_loss: 0.2718\n",
      "Epoch 466/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1791 - val_loss: 1.0490\n",
      "Epoch 467/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5335 - val_loss: 0.2516\n",
      "Epoch 468/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0856 - val_loss: 0.2130\n",
      "Epoch 469/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0571 - val_loss: 0.1369\n",
      "Epoch 470/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0834 - val_loss: 0.1630\n",
      "Epoch 471/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0579 - val_loss: 0.1427\n",
      "Epoch 472/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0514 - val_loss: 0.1554\n",
      "Epoch 473/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0623 - val_loss: 0.1633\n",
      "Epoch 474/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1111 - val_loss: 0.6035\n",
      "Epoch 475/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1801 - val_loss: 0.1822\n",
      "Epoch 476/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0659 - val_loss: 0.1456\n",
      "Epoch 477/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0502 - val_loss: 0.1141\n",
      "Epoch 478/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0503 - val_loss: 0.1234\n",
      "Epoch 479/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0532 - val_loss: 0.1045\n",
      "Epoch 480/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0370 - val_loss: 0.1773\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0424 - val_loss: 0.1237\n",
      "Epoch 482/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0564 - val_loss: 0.1404\n",
      "Epoch 483/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0478 - val_loss: 0.1776\n",
      "Epoch 484/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0541 - val_loss: 0.1193\n",
      "Epoch 485/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0496 - val_loss: 0.1174\n",
      "Epoch 486/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0379 - val_loss: 0.1345\n",
      "Epoch 487/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0390 - val_loss: 0.1432\n",
      "Epoch 488/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0592 - val_loss: 0.1184\n",
      "Epoch 489/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0779 - val_loss: 0.2922\n",
      "Epoch 490/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0661 - val_loss: 0.1148\n",
      "Epoch 491/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0523 - val_loss: 0.1162\n",
      "Epoch 492/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0433 - val_loss: 0.1139\n",
      "Epoch 493/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0419 - val_loss: 0.1277\n",
      "Epoch 494/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.1316\n",
      "Epoch 495/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.1145\n",
      "Epoch 496/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0522 - val_loss: 0.2449\n",
      "Epoch 497/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.1629\n",
      "Epoch 498/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0903 - val_loss: 0.1026\n",
      "Epoch 499/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0530 - val_loss: 0.1301\n",
      "Epoch 500/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0820 - val_loss: 0.1840\n",
      "Epoch 501/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0737 - val_loss: 0.0950\n",
      "Epoch 502/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.1219\n",
      "Epoch 503/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1479 - val_loss: 0.1157\n",
      "Epoch 504/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0750 - val_loss: 0.1475\n",
      "Epoch 505/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0637 - val_loss: 0.1430\n",
      "Epoch 506/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0902 - val_loss: 0.1220\n",
      "Epoch 507/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0501 - val_loss: 0.1221\n",
      "Epoch 508/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0707 - val_loss: 0.1220\n",
      "Epoch 509/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0761 - val_loss: 0.0951\n",
      "Epoch 510/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0511 - val_loss: 0.1003\n",
      "Epoch 511/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0642 - val_loss: 0.1527\n",
      "Epoch 512/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0941 - val_loss: 0.3230\n",
      "Epoch 513/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2883 - val_loss: 0.3520\n",
      "Epoch 514/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5780 - val_loss: 1.0186\n",
      "Epoch 515/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2463 - val_loss: 0.1054\n",
      "Epoch 516/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0451 - val_loss: 0.1059\n",
      "Epoch 517/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0428 - val_loss: 0.1014\n",
      "Epoch 518/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.1410\n",
      "Epoch 519/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0534 - val_loss: 0.1181\n",
      "Epoch 520/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0541 - val_loss: 0.1117\n",
      "Epoch 521/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0385 - val_loss: 0.1142\n",
      "Epoch 522/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0414 - val_loss: 0.1411\n",
      "Epoch 523/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0617 - val_loss: 0.1079\n",
      "Epoch 524/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0406 - val_loss: 0.1111\n",
      "Epoch 525/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0377 - val_loss: 0.1659\n",
      "Epoch 526/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.1029\n",
      "Epoch 527/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0411 - val_loss: 0.0888\n",
      "Epoch 528/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0353 - val_loss: 0.1139\n",
      "Epoch 529/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0325 - val_loss: 0.2545\n",
      "Epoch 530/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0872 - val_loss: 0.1276\n",
      "Epoch 531/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0556 - val_loss: 0.1086\n",
      "Epoch 532/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0465 - val_loss: 0.0927\n",
      "Epoch 533/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0538 - val_loss: 0.1495\n",
      "Epoch 534/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0372 - val_loss: 0.0922\n",
      "Epoch 535/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0425 - val_loss: 0.1505\n",
      "Epoch 536/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0538 - val_loss: 0.0903\n",
      "Epoch 537/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0469 - val_loss: 0.0947\n",
      "Epoch 538/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0777 - val_loss: 0.1226\n",
      "Epoch 539/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.0962\n",
      "Epoch 540/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0425 - val_loss: 0.0949\n",
      "Epoch 541/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0484 - val_loss: 0.1815\n",
      "Epoch 542/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0765 - val_loss: 0.0881\n",
      "Epoch 543/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.1041\n",
      "Epoch 544/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0485 - val_loss: 0.0945\n",
      "Epoch 545/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0737 - val_loss: 0.3380\n",
      "Epoch 546/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0854 - val_loss: 0.1263\n",
      "Epoch 547/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0633 - val_loss: 0.1129\n",
      "Epoch 548/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0970 - val_loss: 0.1283\n",
      "Epoch 549/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0586 - val_loss: 0.0928\n",
      "Epoch 550/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0569 - val_loss: 0.1307\n",
      "Epoch 551/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1033 - val_loss: 0.1361\n",
      "Epoch 552/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1607 - val_loss: 0.4029\n",
      "Epoch 553/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2974 - val_loss: 0.2609\n",
      "Epoch 554/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1370 - val_loss: 0.3083\n",
      "Epoch 555/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1668 - val_loss: 0.1504\n",
      "Epoch 556/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1432 - val_loss: 0.1417\n",
      "Epoch 557/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1171 - val_loss: 0.2864\n",
      "Epoch 558/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1556 - val_loss: 0.3122\n",
      "Epoch 559/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0963 - val_loss: 0.0924\n",
      "Epoch 560/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0528 - val_loss: 0.1380\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0465 - val_loss: 0.0946\n",
      "Epoch 562/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0367 - val_loss: 0.1276\n",
      "Epoch 563/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0503 - val_loss: 0.0931\n",
      "Epoch 564/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.1274\n",
      "Epoch 565/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.0898\n",
      "Epoch 566/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0592 - val_loss: 0.1418\n",
      "Epoch 567/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0750 - val_loss: 0.1368\n",
      "Epoch 568/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.0892\n",
      "Epoch 569/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0390 - val_loss: 0.0819\n",
      "Epoch 570/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0337 - val_loss: 0.0985\n",
      "Epoch 571/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.1027\n",
      "Epoch 572/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0390 - val_loss: 0.1059\n",
      "Epoch 573/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0927\n",
      "Epoch 574/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0522 - val_loss: 0.0879\n",
      "Epoch 575/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0372 - val_loss: 0.0922\n",
      "Epoch 576/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0348 - val_loss: 0.0726\n",
      "Epoch 577/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0337 - val_loss: 0.0845\n",
      "Epoch 578/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.1075\n",
      "Epoch 579/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.1074\n",
      "Epoch 580/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0473 - val_loss: 0.0817\n",
      "Epoch 581/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0384 - val_loss: 0.0852\n",
      "Epoch 582/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0720 - val_loss: 0.0886\n",
      "Epoch 583/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0671 - val_loss: 0.1267\n",
      "Epoch 584/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0574 - val_loss: 0.1108\n",
      "Epoch 585/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0563 - val_loss: 0.1084\n",
      "Epoch 586/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1327 - val_loss: 0.2824\n",
      "Epoch 587/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0983 - val_loss: 0.1754\n",
      "Epoch 588/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0493 - val_loss: 0.0721\n",
      "Epoch 589/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0393 - val_loss: 0.1034\n",
      "Epoch 590/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0481 - val_loss: 0.0795\n",
      "Epoch 591/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0343 - val_loss: 0.0918\n",
      "Epoch 592/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.1051\n",
      "Epoch 593/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2032 - val_loss: 0.7555\n",
      "Epoch 594/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.0955\n",
      "Epoch 595/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0887 - val_loss: 0.2390\n",
      "Epoch 596/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0557 - val_loss: 0.1268\n",
      "Epoch 597/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0475 - val_loss: 0.0961\n",
      "Epoch 598/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0566 - val_loss: 0.1857\n",
      "Epoch 599/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0753 - val_loss: 0.1946\n",
      "Epoch 600/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1151 - val_loss: 0.1467\n",
      "Epoch 601/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0585 - val_loss: 0.0780\n",
      "Epoch 602/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0303 - val_loss: 0.0688\n",
      "Epoch 603/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.0733\n",
      "Epoch 604/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0332 - val_loss: 0.0745\n",
      "Epoch 605/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0574 - val_loss: 0.0770\n",
      "Epoch 606/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0356 - val_loss: 0.0751\n",
      "Epoch 607/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0916\n",
      "Epoch 608/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0450 - val_loss: 0.0810\n",
      "Epoch 609/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0372 - val_loss: 0.1163\n",
      "Epoch 610/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0390 - val_loss: 0.0907\n",
      "Epoch 611/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0491 - val_loss: 0.1248\n",
      "Epoch 612/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0572 - val_loss: 0.1089\n",
      "Epoch 613/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0846 - val_loss: 0.1182\n",
      "Epoch 614/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.1092\n",
      "Epoch 615/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0617 - val_loss: 0.1011\n",
      "Epoch 616/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1104 - val_loss: 0.1816\n",
      "Epoch 617/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0881 - val_loss: 0.0880\n",
      "Epoch 618/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0542 - val_loss: 0.0778\n",
      "Epoch 619/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0514 - val_loss: 0.0994\n",
      "Epoch 620/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.1628\n",
      "Epoch 621/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0546 - val_loss: 0.1167\n",
      "Epoch 622/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0702 - val_loss: 0.1768\n",
      "Epoch 623/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0600 - val_loss: 0.1552\n",
      "Epoch 624/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0463 - val_loss: 0.0999\n",
      "Epoch 625/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0550 - val_loss: 0.2245\n",
      "Epoch 626/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0558 - val_loss: 0.0990\n",
      "Epoch 627/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.1074\n",
      "Epoch 628/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0605 - val_loss: 0.1749\n",
      "Epoch 629/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2594 - val_loss: 0.2309\n",
      "Epoch 630/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0933 - val_loss: 0.2974\n",
      "Epoch 631/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2503 - val_loss: 0.0910\n",
      "Epoch 632/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0568 - val_loss: 0.1951\n",
      "Epoch 633/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1811 - val_loss: 0.1403\n",
      "Epoch 634/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0545 - val_loss: 0.1449\n",
      "Epoch 635/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0945 - val_loss: 0.1374\n",
      "Epoch 636/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0629 - val_loss: 0.1088\n",
      "Epoch 637/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0634 - val_loss: 0.0939\n",
      "Epoch 638/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0567 - val_loss: 0.0901\n",
      "Epoch 639/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.1055\n",
      "Epoch 640/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0373 - val_loss: 0.1028\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0559 - val_loss: 0.0702\n",
      "Epoch 642/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0303 - val_loss: 0.0705\n",
      "Epoch 643/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0332 - val_loss: 0.0741\n",
      "Epoch 644/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0533 - val_loss: 0.1112\n",
      "Epoch 645/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0479 - val_loss: 0.0777\n",
      "Epoch 646/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0706\n",
      "Epoch 647/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0457 - val_loss: 0.1255\n",
      "Epoch 648/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0543 - val_loss: 0.0994\n",
      "Epoch 649/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0503 - val_loss: 0.1247\n",
      "Epoch 650/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.0737\n",
      "Epoch 651/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0763\n",
      "Epoch 652/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0861 - val_loss: 0.0886\n",
      "Epoch 653/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0487 - val_loss: 0.0687\n",
      "Epoch 654/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0700\n",
      "Epoch 655/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0335 - val_loss: 0.0765\n",
      "Epoch 656/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0349 - val_loss: 0.0663\n",
      "Epoch 657/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0374 - val_loss: 0.0917\n",
      "Epoch 658/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0436 - val_loss: 0.0766\n",
      "Epoch 659/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0454 - val_loss: 0.0983\n",
      "Epoch 660/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0393 - val_loss: 0.0725\n",
      "Epoch 661/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0404 - val_loss: 0.1154\n",
      "Epoch 662/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0457 - val_loss: 0.1339\n",
      "Epoch 663/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0425 - val_loss: 0.0856\n",
      "Epoch 664/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.2414\n",
      "Epoch 665/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0671 - val_loss: 0.4857\n",
      "Epoch 666/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3412 - val_loss: 1.5858\n",
      "Epoch 667/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3446 - val_loss: 0.1166\n",
      "Epoch 668/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0582 - val_loss: 0.2387\n",
      "Epoch 669/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1241 - val_loss: 0.1479\n",
      "Epoch 670/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0821 - val_loss: 0.1524\n",
      "Epoch 671/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0642 - val_loss: 0.2137\n",
      "Epoch 672/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2000 - val_loss: 0.1367\n",
      "Epoch 673/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0905 - val_loss: 0.1850\n",
      "Epoch 674/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0873 - val_loss: 0.1031\n",
      "Epoch 675/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0592 - val_loss: 0.2121\n",
      "Epoch 676/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0702 - val_loss: 0.1445\n",
      "Epoch 677/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0724 - val_loss: 0.1893\n",
      "Epoch 678/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2658 - val_loss: 0.5220\n",
      "Epoch 679/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2054 - val_loss: 0.1401\n",
      "Epoch 680/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0613 - val_loss: 0.0902\n",
      "Epoch 681/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0380 - val_loss: 0.0904\n",
      "Epoch 682/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0506 - val_loss: 0.1292\n",
      "Epoch 683/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0582 - val_loss: 0.0791\n",
      "Epoch 684/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0382 - val_loss: 0.0687\n",
      "Epoch 685/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0376 - val_loss: 0.0753\n",
      "Epoch 686/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.0687\n",
      "Epoch 687/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0418 - val_loss: 0.0718\n",
      "Epoch 688/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0316 - val_loss: 0.0654\n",
      "Epoch 689/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0509 - val_loss: 0.0739\n",
      "Epoch 690/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0391 - val_loss: 0.0684\n",
      "Epoch 691/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0485 - val_loss: 0.1289\n",
      "Epoch 692/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0510 - val_loss: 0.0953\n",
      "Epoch 693/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0426 - val_loss: 0.0703\n",
      "Epoch 694/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.1638\n",
      "Epoch 695/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0707 - val_loss: 0.2369\n",
      "Epoch 696/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1228 - val_loss: 0.0874\n",
      "Epoch 697/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0494 - val_loss: 0.0943\n",
      "Epoch 698/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0647 - val_loss: 0.0772\n",
      "Epoch 699/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0664\n",
      "Epoch 700/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0674\n",
      "Epoch 701/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0335 - val_loss: 0.0642\n",
      "Epoch 702/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0362 - val_loss: 0.0662\n",
      "Epoch 703/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0357 - val_loss: 0.0624\n",
      "Epoch 704/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0525 - val_loss: 0.2317\n",
      "Epoch 705/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0528 - val_loss: 0.0728\n",
      "Epoch 706/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0379 - val_loss: 0.0802\n",
      "Epoch 707/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0414 - val_loss: 0.0579\n",
      "Epoch 708/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0426 - val_loss: 0.0692\n",
      "Epoch 709/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0366 - val_loss: 0.0826\n",
      "Epoch 710/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0333 - val_loss: 0.0645\n",
      "Epoch 711/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0295 - val_loss: 0.0584\n",
      "Epoch 712/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0375 - val_loss: 0.0604\n",
      "Epoch 713/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0343 - val_loss: 0.0767\n",
      "Epoch 714/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0389 - val_loss: 0.1382\n",
      "Epoch 715/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0587 - val_loss: 0.1495\n",
      "Epoch 716/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0578 - val_loss: 0.0636\n",
      "Epoch 717/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0569 - val_loss: 0.1182\n",
      "Epoch 718/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0519 - val_loss: 0.0656\n",
      "Epoch 719/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.0679\n",
      "Epoch 720/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.0875\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0478 - val_loss: 0.0620\n",
      "Epoch 722/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0386 - val_loss: 0.0645\n",
      "Epoch 723/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0594 - val_loss: 0.0834\n",
      "Epoch 724/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0442 - val_loss: 0.0820\n",
      "Epoch 725/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0354 - val_loss: 0.0641\n",
      "Epoch 726/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0400 - val_loss: 0.0689\n",
      "Epoch 727/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0387 - val_loss: 0.0805\n",
      "Epoch 728/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0608 - val_loss: 0.1147\n",
      "Epoch 729/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0529 - val_loss: 0.1752\n",
      "Epoch 730/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0561 - val_loss: 0.1053\n",
      "Epoch 731/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0390 - val_loss: 0.0592\n",
      "Epoch 732/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0397 - val_loss: 0.0596\n",
      "Epoch 733/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0349 - val_loss: 0.0766\n",
      "Epoch 734/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0375 - val_loss: 0.0576\n",
      "Epoch 735/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0686\n",
      "Epoch 736/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1170 - val_loss: 0.0642\n",
      "Epoch 737/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.0884\n",
      "Epoch 738/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.0674\n",
      "Epoch 739/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0512 - val_loss: 0.0625\n",
      "Epoch 740/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0380 - val_loss: 0.0627\n",
      "Epoch 741/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0576\n",
      "Epoch 742/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.0800\n",
      "Epoch 743/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0533 - val_loss: 0.1598\n",
      "Epoch 744/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0591 - val_loss: 0.0608\n",
      "Epoch 745/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0362 - val_loss: 0.0860\n",
      "Epoch 746/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0552 - val_loss: 0.0595\n",
      "Epoch 747/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0486 - val_loss: 0.0816\n",
      "Epoch 748/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0440 - val_loss: 0.0654\n",
      "Epoch 749/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0510 - val_loss: 0.0788\n",
      "Epoch 750/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0650 - val_loss: 0.0787\n",
      "Epoch 751/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.1488\n",
      "Epoch 752/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0578 - val_loss: 0.0669\n",
      "Epoch 753/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0351 - val_loss: 0.0728\n",
      "Epoch 754/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0368 - val_loss: 0.0844\n",
      "Epoch 755/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0406 - val_loss: 0.0763\n",
      "Epoch 756/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0553 - val_loss: 0.0592\n",
      "Epoch 757/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.0765\n",
      "Epoch 758/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1167 - val_loss: 0.1398\n",
      "Epoch 759/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0652 - val_loss: 0.1001\n",
      "Epoch 760/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0500 - val_loss: 0.0597\n",
      "Epoch 761/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0445 - val_loss: 0.0589\n",
      "Epoch 762/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.0696\n",
      "Epoch 763/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0470 - val_loss: 0.0670\n",
      "Epoch 764/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0504 - val_loss: 0.0604\n",
      "Epoch 765/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340 - val_loss: 0.0604\n",
      "Epoch 766/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 767/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0505 - val_loss: 0.1650\n",
      "Epoch 768/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0667 - val_loss: 0.0705\n",
      "Epoch 769/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0546\n",
      "Epoch 770/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0434 - val_loss: 0.0588\n",
      "Epoch 771/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0367 - val_loss: 0.0677\n",
      "Epoch 772/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0581\n",
      "Epoch 773/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0573 - val_loss: 0.0622\n",
      "Epoch 774/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.0523\n",
      "Epoch 775/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.0585\n",
      "Epoch 776/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0433 - val_loss: 0.0589\n",
      "Epoch 777/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0475 - val_loss: 0.0651\n",
      "Epoch 778/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0393 - val_loss: 0.0714\n",
      "Epoch 779/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0486 - val_loss: 0.0708\n",
      "Epoch 780/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.0625\n",
      "Epoch 781/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0732 - val_loss: 0.0988\n",
      "Epoch 782/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0461 - val_loss: 0.0778\n",
      "Epoch 783/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0563 - val_loss: 0.1774\n",
      "Epoch 784/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0513 - val_loss: 0.0745\n",
      "Epoch 785/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.0659\n",
      "Epoch 786/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.0605\n",
      "Epoch 787/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.0549\n",
      "Epoch 788/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0306 - val_loss: 0.0617\n",
      "Epoch 789/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0394 - val_loss: 0.0769\n",
      "Epoch 790/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0367 - val_loss: 0.0795\n",
      "Epoch 791/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0376 - val_loss: 0.0589\n",
      "Epoch 792/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0350 - val_loss: 0.0862\n",
      "Epoch 793/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0356 - val_loss: 0.0750\n",
      "Epoch 794/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0389 - val_loss: 0.0625\n",
      "Epoch 795/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.0553\n",
      "Epoch 796/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0295 - val_loss: 0.0504\n",
      "Epoch 797/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.1163\n",
      "Epoch 798/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0625 - val_loss: 0.0728\n",
      "Epoch 799/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0410 - val_loss: 0.0785\n",
      "Epoch 800/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0742 - val_loss: 0.0660\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0820 - val_loss: 0.0696\n",
      "Epoch 802/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.1042\n",
      "Epoch 803/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0571 - val_loss: 0.0625\n",
      "Epoch 804/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0345 - val_loss: 0.0635\n",
      "Epoch 805/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0464 - val_loss: 0.1006\n",
      "Epoch 806/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0443 - val_loss: 0.0597\n",
      "Epoch 807/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0573 - val_loss: 0.0631\n",
      "Epoch 808/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0561 - val_loss: 0.0629\n",
      "Epoch 809/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0391 - val_loss: 0.0612\n",
      "Epoch 810/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0539 - val_loss: 0.0603\n",
      "Epoch 811/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0523 - val_loss: 0.1096\n",
      "Epoch 812/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 813/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0522 - val_loss: 0.0557\n",
      "Epoch 814/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0484 - val_loss: 0.0672\n",
      "Epoch 815/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0396 - val_loss: 0.0630\n",
      "Epoch 816/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0379 - val_loss: 0.0555\n",
      "Epoch 817/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0380 - val_loss: 0.0563\n",
      "Epoch 818/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0338 - val_loss: 0.0564\n",
      "Epoch 819/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0418 - val_loss: 0.1342\n",
      "Epoch 820/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0408 - val_loss: 0.0590\n",
      "Epoch 821/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0554 - val_loss: 0.0735\n",
      "Epoch 822/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0616\n",
      "Epoch 823/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0354 - val_loss: 0.0542\n",
      "Epoch 824/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0564 - val_loss: 0.0898\n",
      "Epoch 825/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0489 - val_loss: 0.0565\n",
      "Epoch 826/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0366 - val_loss: 0.0566\n",
      "Epoch 827/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0436 - val_loss: 0.0622\n",
      "Epoch 828/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0319 - val_loss: 0.0614\n",
      "Epoch 829/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0390 - val_loss: 0.0877\n",
      "Epoch 830/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0357 - val_loss: 0.0559\n",
      "Epoch 831/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0602 - val_loss: 0.1337\n",
      "Epoch 832/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0979 - val_loss: 0.0742\n",
      "Epoch 833/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0662 - val_loss: 0.1661\n",
      "Epoch 834/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0577 - val_loss: 0.0561\n",
      "Epoch 835/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0363 - val_loss: 0.0537\n",
      "Epoch 836/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0428 - val_loss: 0.0704\n",
      "Epoch 837/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0323 - val_loss: 0.0517\n",
      "Epoch 838/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.0633\n",
      "Epoch 839/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0514 - val_loss: 0.0782\n",
      "Epoch 840/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0435 - val_loss: 0.0615\n",
      "Epoch 841/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0450 - val_loss: 0.0913\n",
      "Epoch 842/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0735 - val_loss: 0.2308\n",
      "Epoch 843/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0564 - val_loss: 0.0868\n",
      "Epoch 844/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0353 - val_loss: 0.0823\n",
      "Epoch 845/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0327 - val_loss: 0.0717\n",
      "Epoch 846/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.1181\n",
      "Epoch 847/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0525 - val_loss: 0.1116\n",
      "Epoch 848/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0430 - val_loss: 0.0768\n",
      "Epoch 849/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0307 - val_loss: 0.0568\n",
      "Epoch 850/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0557 - val_loss: 0.0791\n",
      "Epoch 851/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0615 - val_loss: 0.0625\n",
      "Epoch 852/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0342 - val_loss: 0.1086\n",
      "Epoch 853/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0363 - val_loss: 0.0536\n",
      "Epoch 854/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0505 - val_loss: 0.0562\n",
      "Epoch 855/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0379 - val_loss: 0.0540\n",
      "Epoch 856/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0408 - val_loss: 0.0584\n",
      "Epoch 857/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0514\n",
      "Epoch 858/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0446 - val_loss: 0.0835\n",
      "Epoch 859/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0661 - val_loss: 0.0593\n",
      "Epoch 860/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.0644\n",
      "Epoch 861/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.0565\n",
      "Epoch 862/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0814\n",
      "Epoch 863/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0369 - val_loss: 0.0527\n",
      "Epoch 864/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0710 - val_loss: 0.0635\n",
      "Epoch 865/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0340 - val_loss: 0.0590\n",
      "Epoch 866/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0577\n",
      "Epoch 867/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0373 - val_loss: 0.0594\n",
      "Epoch 868/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0761 - val_loss: 0.1346\n",
      "Epoch 869/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0563 - val_loss: 0.0599\n",
      "Epoch 870/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0480 - val_loss: 0.0512\n",
      "Epoch 871/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0478 - val_loss: 0.0479\n",
      "Epoch 872/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0541 - val_loss: 0.0525\n",
      "Epoch 873/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0594 - val_loss: 0.0925\n",
      "Epoch 874/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0372 - val_loss: 0.0505\n",
      "Epoch 875/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.0495\n",
      "Epoch 876/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0352 - val_loss: 0.0965\n",
      "Epoch 877/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0424 - val_loss: 0.0513\n",
      "Epoch 878/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0473 - val_loss: 0.0518\n",
      "Epoch 879/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0298 - val_loss: 0.0566\n",
      "Epoch 880/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.0476\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0474 - val_loss: 0.0729\n",
      "Epoch 882/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0321 - val_loss: 0.0612\n",
      "Epoch 883/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0391 - val_loss: 0.0949\n",
      "Epoch 884/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0543 - val_loss: 0.0746\n",
      "Epoch 885/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0614 - val_loss: 0.1641\n",
      "Epoch 886/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0487 - val_loss: 0.0569\n",
      "Epoch 887/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0322 - val_loss: 0.0646\n",
      "Epoch 888/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 0.0684\n",
      "Epoch 889/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0393 - val_loss: 0.0602\n",
      "Epoch 890/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0359 - val_loss: 0.0544\n",
      "Epoch 891/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0526 - val_loss: 0.0724\n",
      "Epoch 892/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0466 - val_loss: 0.0923\n",
      "Epoch 893/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0498 - val_loss: 0.0640\n",
      "Epoch 894/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0576 - val_loss: 0.0600\n",
      "Epoch 895/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0801\n",
      "Epoch 896/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0343 - val_loss: 0.0630\n",
      "Epoch 897/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0369 - val_loss: 0.0940\n",
      "Epoch 898/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0371 - val_loss: 0.0487\n",
      "Epoch 899/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0493 - val_loss: 0.0751\n",
      "Epoch 900/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0500 - val_loss: 0.0673\n",
      "Epoch 901/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0363 - val_loss: 0.0470\n",
      "Epoch 902/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0808\n",
      "Epoch 903/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.1301\n",
      "Epoch 904/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0794 - val_loss: 0.0541\n",
      "Epoch 905/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0461 - val_loss: 0.2688\n",
      "Epoch 906/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0957 - val_loss: 0.0646\n",
      "Epoch 907/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0734 - val_loss: 0.0655\n",
      "Epoch 908/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0387 - val_loss: 0.0546\n",
      "Epoch 909/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0529 - val_loss: 0.0521\n",
      "Epoch 910/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.0534\n",
      "Epoch 911/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.0525\n",
      "Epoch 912/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0368 - val_loss: 0.1662\n",
      "Epoch 913/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0583 - val_loss: 0.1009\n",
      "Epoch 914/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0387 - val_loss: 0.0486\n",
      "Epoch 915/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0424 - val_loss: 0.0542\n",
      "Epoch 916/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0377 - val_loss: 0.0525\n",
      "Epoch 917/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.0522\n",
      "Epoch 918/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0339 - val_loss: 0.0785\n",
      "Epoch 919/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.0531\n",
      "Epoch 920/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0323 - val_loss: 0.0778\n",
      "Epoch 921/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0389 - val_loss: 0.0546\n",
      "Epoch 922/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0327 - val_loss: 0.0588\n",
      "Epoch 923/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0324 - val_loss: 0.0533\n",
      "Epoch 924/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0366 - val_loss: 0.0520\n",
      "Epoch 925/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0487 - val_loss: 0.0600\n",
      "Epoch 926/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.0494\n",
      "Epoch 927/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.1407\n",
      "Epoch 928/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1052 - val_loss: 0.1453\n",
      "Epoch 929/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0698 - val_loss: 0.0649\n",
      "Epoch 930/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0836\n",
      "Epoch 931/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0357 - val_loss: 0.0507\n",
      "Epoch 932/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0486\n",
      "Epoch 933/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0333 - val_loss: 0.1045\n",
      "Epoch 934/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0431 - val_loss: 0.0657\n",
      "Epoch 935/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0494\n",
      "Epoch 936/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0354 - val_loss: 0.0882\n",
      "Epoch 937/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0443 - val_loss: 0.0523\n",
      "Epoch 938/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0318 - val_loss: 0.0853\n",
      "Epoch 939/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0370 - val_loss: 0.0520\n",
      "Epoch 940/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0282 - val_loss: 0.0706\n",
      "Epoch 941/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0404 - val_loss: 0.0560\n",
      "Epoch 942/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0357 - val_loss: 0.1124\n",
      "Epoch 943/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0529 - val_loss: 0.0511\n",
      "Epoch 944/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.1249\n",
      "Epoch 945/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0587 - val_loss: 0.0809\n",
      "Epoch 946/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0380 - val_loss: 0.0605\n",
      "Epoch 947/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0513 - val_loss: 0.0977\n",
      "Epoch 948/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0518 - val_loss: 0.0494\n",
      "Epoch 949/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 0.0570\n",
      "Epoch 950/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.0524\n",
      "Epoch 951/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0481 - val_loss: 0.0548\n",
      "Epoch 952/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0379 - val_loss: 0.0536\n",
      "Epoch 953/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0551\n",
      "Epoch 954/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0532\n",
      "Epoch 955/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0384 - val_loss: 0.1467\n",
      "Epoch 956/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0542 - val_loss: 0.0657\n",
      "Epoch 957/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0484 - val_loss: 0.0665\n",
      "Epoch 958/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0491 - val_loss: 0.0687\n",
      "Epoch 959/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0392 - val_loss: 0.0684\n",
      "Epoch 960/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0534 - val_loss: 0.0702\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.0654\n",
      "Epoch 962/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0702 - val_loss: 0.1634\n",
      "Epoch 963/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0526 - val_loss: 0.1327\n",
      "Epoch 964/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0573 - val_loss: 0.0570\n",
      "Epoch 965/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0384 - val_loss: 0.0512\n",
      "Epoch 966/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0601\n",
      "Epoch 967/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0499 - val_loss: 0.0650\n",
      "Epoch 968/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0858 - val_loss: 0.0674\n",
      "Epoch 969/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0531 - val_loss: 0.0581\n",
      "Epoch 970/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0334 - val_loss: 0.0516\n",
      "Epoch 971/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0381 - val_loss: 0.0597\n",
      "Epoch 972/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0351 - val_loss: 0.0489\n",
      "Epoch 973/1000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0308 - val_loss: 0.0489\n",
      "Epoch 974/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.0917\n",
      "Epoch 975/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0362 - val_loss: 0.0501\n",
      "Epoch 976/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0318 - val_loss: 0.1081\n",
      "Epoch 977/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0626 - val_loss: 0.0559\n",
      "Epoch 978/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0463 - val_loss: 0.0653\n",
      "Epoch 979/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.0545\n",
      "Epoch 980/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0501 - val_loss: 0.0518\n",
      "Epoch 981/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0511\n",
      "Epoch 982/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0295 - val_loss: 0.0927\n",
      "Epoch 983/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0576\n",
      "Epoch 984/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0480 - val_loss: 0.0614\n",
      "Epoch 985/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0491 - val_loss: 0.0518\n",
      "Epoch 986/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.0504\n",
      "Epoch 987/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0298 - val_loss: 0.0782\n",
      "Epoch 988/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0380 - val_loss: 0.0498\n",
      "Epoch 989/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0367 - val_loss: 0.0487\n",
      "Epoch 990/1000\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0421 - val_loss: 0.1370\n",
      "Epoch 991/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.0656\n",
      "Epoch 992/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0661 - val_loss: 0.1876\n",
      "Epoch 993/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1130 - val_loss: 0.0723\n",
      "Epoch 994/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0389 - val_loss: 0.0928\n",
      "Epoch 995/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0450 - val_loss: 0.0495\n",
      "Epoch 996/1000\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0415 - val_loss: 0.0539\n",
      "Epoch 997/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0499\n",
      "Epoch 998/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0472 - val_loss: 0.0506\n",
      "Epoch 999/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0374 - val_loss: 0.0492\n",
      "Epoch 1000/1000\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c6566ecad0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(len(features),)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)  # 2 output neurons for longitude and latitude\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=1000, batch_size=12, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fdf4b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#predict the model\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b872e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_predictions = predictions[:, 0] \n",
    "lat_predictions = predictions[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d24f120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Longitude   Latitude                   geometry\n",
      "0    -4.673484  48.175106  POINT (-4.67348 48.17511)\n",
      "1    -4.690993  48.344479  POINT (-4.69099 48.34448)\n",
      "2    -4.691700  48.351322  POINT (-4.69170 48.35132)\n",
      "3    -4.686751  48.303448  POINT (-4.68675 48.30345)\n",
      "4    -4.681598  48.253590  POINT (-4.68160 48.25359)\n",
      "..         ...        ...                        ...\n",
      "235  -4.698176  48.413963  POINT (-4.69818 48.41396)\n",
      "236  -4.697096  48.403515  POINT (-4.69710 48.40351)\n",
      "237  -4.709512  48.523628  POINT (-4.70951 48.52363)\n",
      "238  -4.690327  48.338039  POINT (-4.69033 48.33804)\n",
      "239  -4.689377  48.328850  POINT (-4.68938 48.32885)\n",
      "\n",
      "[240 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Point\n",
    "#create a geometry column using Point objects from the shapley library\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(lon_predictions, lat_predictions)]\n",
    "\n",
    "#create the GeoDataFrame\n",
    "geo_df = gpd.GeoDataFrame({\n",
    "    'Longitude': lon_predictions,\n",
    "    'Latitude': lat_predictions\n",
    "}, geometry=geometry)\n",
    "\n",
    "print(geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dee106c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Longitude   Latitude                   geometry\n",
      "0    -4.551695  48.344520  POINT (-4.55169 48.34452)\n",
      "1    -4.733975  48.301247  POINT (-4.73398 48.30125)\n",
      "2    -4.885512  48.404390  POINT (-4.88551 48.40439)\n",
      "3    -4.924165  48.405033  POINT (-4.92417 48.40503)\n",
      "4    -4.550415  48.351140  POINT (-4.55042 48.35114)\n",
      "..         ...        ...                        ...\n",
      "795  -4.639665  48.315987  POINT (-4.63966 48.31599)\n",
      "796  -4.547798  48.351620  POINT (-4.54780 48.35162)\n",
      "797  -5.186498  48.084835  POINT (-5.18650 48.08483)\n",
      "798  -4.465165  48.318333  POINT (-4.46516 48.31833)\n",
      "799  -4.773423  48.041780  POINT (-4.77342 48.04178)\n",
      "\n",
      "[800 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "o_geometry = [Point(lon, lat) for lon, lat in zip(original_lon1, original_lat1)]\n",
    "\n",
    "#create the GeoDataFrame\n",
    "o_geo_df = gpd.GeoDataFrame({\n",
    "    'Longitude': original_lon1,\n",
    "    'Latitude': original_lat1\n",
    "}, geometry=o_geometry)\n",
    "\n",
    "print(o_geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bae9e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation\n",
    "\n",
    "#create a map centered around the mean coordinates of the points\n",
    "mean_coords = geo_df['geometry'].unary_union.centroid\n",
    "m = folium.Map(location=[mean_coords.y, mean_coords.x], zoom_start=6)\n",
    "original_color = (255, 0, 0)  # Red\n",
    "predicted_color = (0, 0, 255)  # Blue\n",
    "\n",
    "#add original geometry\n",
    "for index, row in o_geo_df.iterrows():\n",
    "    lat, lon = row['geometry'].y, row['geometry'].x  # Use 'geometry' here\n",
    "    folium.Marker([lat, lon], icon=folium.Icon(color='blue')).add_to(m)\n",
    "\n",
    "#add predictions markers\n",
    "for index, row in geo_df.iterrows():\n",
    "    lat, lon = row['geometry'].y, row['geometry'].x\n",
    "    folium.Marker([lat, lon], icon=folium.Icon(color=\"red\")).add_to(m)\n",
    "\n",
    "#display the map\n",
    "#m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6093ca",
   "metadata": {},
   "source": [
    "Here is a general breakdown on vessel prediction using data visualisation. The abouve could indicate that vessels, in general, are coming into port as the data markers seem to congregate around port areas. However, some outliers show some predictions as being on land - we will analyse a vessel showing some inconsistent results shoiwng \"land prediction abnormality\" in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed207258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_862b2d00f8e404fff47bd42fb09b1d2d {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_862b2d00f8e404fff47bd42fb09b1d2d&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_862b2d00f8e404fff47bd42fb09b1d2d = L.map(\n",
       "                &quot;map_862b2d00f8e404fff47bd42fb09b1d2d&quot;,\n",
       "                {\n",
       "                    center: [48.332474535363886, -4.71842818362454],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 6,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_c17ee5c1148b3854eba102356c7f5f71 = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var marker_521a4698b16cf366e1cb615d1a2ce07d = L.marker(\n",
       "                [48.3463668213243, -4.785551345067117],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_922b00ac739b5be89218e5405c27637e = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_521a4698b16cf366e1cb615d1a2ce07d.setIcon(icon_922b00ac739b5be89218e5405c27637e);\n",
       "        \n",
       "    \n",
       "        var popup_2b2a6905e7c85f884dd9984f23b0aeba = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_8d76a24ba2be8eda69a75431def99c25 = $(`&lt;div id=&quot;html_8d76a24ba2be8eda69a75431def99c25&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Original 0&lt;/div&gt;`)[0];\n",
       "                popup_2b2a6905e7c85f884dd9984f23b0aeba.setContent(html_8d76a24ba2be8eda69a75431def99c25);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_521a4698b16cf366e1cb615d1a2ce07d.bindPopup(popup_2b2a6905e7c85f884dd9984f23b0aeba)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_57d8964fb1eb58336a125daf7e3751b2 = L.marker(\n",
       "                [48.202787724790944, -4.345142114300299],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_9c06d613d29b3d6a23b0b597dc23e387 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_57d8964fb1eb58336a125daf7e3751b2.setIcon(icon_9c06d613d29b3d6a23b0b597dc23e387);\n",
       "        \n",
       "    \n",
       "        var popup_da199eefc3b0af991e6ef6b670fa891e = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_03690e14273ffb36bd0f4315ca148119 = $(`&lt;div id=&quot;html_03690e14273ffb36bd0f4315ca148119&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Original 1&lt;/div&gt;`)[0];\n",
       "                popup_da199eefc3b0af991e6ef6b670fa891e.setContent(html_03690e14273ffb36bd0f4315ca148119);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_57d8964fb1eb58336a125daf7e3751b2.bindPopup(popup_da199eefc3b0af991e6ef6b670fa891e)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_2af4a6c2110942f720978a9247b1f2b0 = L.marker(\n",
       "                [48.39332963456571, -4.900966747988034],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_d5a0f098713570a2b11907000013ad01 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_2af4a6c2110942f720978a9247b1f2b0.setIcon(icon_d5a0f098713570a2b11907000013ad01);\n",
       "        \n",
       "    \n",
       "        var popup_f462cdd3bd5f7de7926469f67c1209d1 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_5f58066404c968a58f4be0b32c5f9ba0 = $(`&lt;div id=&quot;html_5f58066404c968a58f4be0b32c5f9ba0&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Original 2&lt;/div&gt;`)[0];\n",
       "                popup_f462cdd3bd5f7de7926469f67c1209d1.setContent(html_5f58066404c968a58f4be0b32c5f9ba0);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_2af4a6c2110942f720978a9247b1f2b0.bindPopup(popup_f462cdd3bd5f7de7926469f67c1209d1)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_cd81fb0ff0f28fb6c2b4c304ee55550d = L.marker(\n",
       "                [48.32789764914367, -4.6161503299121],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_4a3e4117bb5d5e1abcbd848b8ee3538f = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_cd81fb0ff0f28fb6c2b4c304ee55550d.setIcon(icon_4a3e4117bb5d5e1abcbd848b8ee3538f);\n",
       "        \n",
       "    \n",
       "        var popup_7473a1cdd7ff78403e2f7f893f206514 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_4e73f2c6159ec9842821ce13efff8827 = $(`&lt;div id=&quot;html_4e73f2c6159ec9842821ce13efff8827&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Original 3&lt;/div&gt;`)[0];\n",
       "                popup_7473a1cdd7ff78403e2f7f893f206514.setContent(html_4e73f2c6159ec9842821ce13efff8827);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_cd81fb0ff0f28fb6c2b4c304ee55550d.bindPopup(popup_7473a1cdd7ff78403e2f7f893f206514)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_d30c2c0238159008a40ba0ed848e8fc5 = L.marker(\n",
       "                [48.316235321808456, -4.72356803794207],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_028a68f92ee713ecd57a60ad22fe61b9 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_d30c2c0238159008a40ba0ed848e8fc5.setIcon(icon_028a68f92ee713ecd57a60ad22fe61b9);\n",
       "        \n",
       "    \n",
       "        var popup_9ca93b0d2876a4e30a7e170ab0a018f9 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_862da7cd0520996a51c55a3ba1ba8fd8 = $(`&lt;div id=&quot;html_862da7cd0520996a51c55a3ba1ba8fd8&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Original 4&lt;/div&gt;`)[0];\n",
       "                popup_9ca93b0d2876a4e30a7e170ab0a018f9.setContent(html_862da7cd0520996a51c55a3ba1ba8fd8);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_d30c2c0238159008a40ba0ed848e8fc5.bindPopup(popup_9ca93b0d2876a4e30a7e170ab0a018f9)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_7c72786520b74084d74b48b0be5a2458 = L.marker(\n",
       "                [48.34329846222125, -4.841810186019186],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_346f20efbe20f2dbabd122b5406d7891 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_7c72786520b74084d74b48b0be5a2458.setIcon(icon_346f20efbe20f2dbabd122b5406d7891);\n",
       "        \n",
       "    \n",
       "        var popup_99df4254347bd9a82362fe521695565d = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_4f2d2ac551a209a8f373ae27dad99f35 = $(`&lt;div id=&quot;html_4f2d2ac551a209a8f373ae27dad99f35&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Original 5&lt;/div&gt;`)[0];\n",
       "                popup_99df4254347bd9a82362fe521695565d.setContent(html_4f2d2ac551a209a8f373ae27dad99f35);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_7c72786520b74084d74b48b0be5a2458.bindPopup(popup_99df4254347bd9a82362fe521695565d)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_64189244feb4a8fc29e8d0ec7f8b5440 = L.marker(\n",
       "                [48.32357489445884, -4.701714984465409],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_3400e865780c6c110501fd726fea7ab8 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;blue&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_64189244feb4a8fc29e8d0ec7f8b5440.setIcon(icon_3400e865780c6c110501fd726fea7ab8);\n",
       "        \n",
       "    \n",
       "        var popup_07f703f147446f6715d9de9615a03a54 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_7ad5b9e5a08ecb3f6f8b130b4693532a = $(`&lt;div id=&quot;html_7ad5b9e5a08ecb3f6f8b130b4693532a&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Original 6&lt;/div&gt;`)[0];\n",
       "                popup_07f703f147446f6715d9de9615a03a54.setContent(html_7ad5b9e5a08ecb3f6f8b130b4693532a);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_64189244feb4a8fc29e8d0ec7f8b5440.bindPopup(popup_07f703f147446f6715d9de9615a03a54)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_7a3a51d2a5c2c1f3ff5adcccb639490a = L.marker(\n",
       "                [48.37447528878864, -4.815090570690129],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_a7bb25751be4341b786a6610cc126eee = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_7a3a51d2a5c2c1f3ff5adcccb639490a.setIcon(icon_a7bb25751be4341b786a6610cc126eee);\n",
       "        \n",
       "    \n",
       "        var popup_b8d1af75e3da60e94b439a4cf39fe1d8 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_ab630c5f8ebd9657d0029feda303af3f = $(`&lt;div id=&quot;html_ab630c5f8ebd9657d0029feda303af3f&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Predicted 0&lt;/div&gt;`)[0];\n",
       "                popup_b8d1af75e3da60e94b439a4cf39fe1d8.setContent(html_ab630c5f8ebd9657d0029feda303af3f);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_7a3a51d2a5c2c1f3ff5adcccb639490a.bindPopup(popup_b8d1af75e3da60e94b439a4cf39fe1d8)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_4ca0e68d32d094c2305cfc3d0dd05067 = L.marker(\n",
       "                [48.337568938850275, -4.786021310461703],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_4def5056d752a905773ac2d8a976ded4 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_4ca0e68d32d094c2305cfc3d0dd05067.setIcon(icon_4def5056d752a905773ac2d8a976ded4);\n",
       "        \n",
       "    \n",
       "        var popup_00f5605d6511947b3f0452ee3e7ed82a = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_8fb4d3ff38a7743f29f5379f7b8c62d2 = $(`&lt;div id=&quot;html_8fb4d3ff38a7743f29f5379f7b8c62d2&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Predicted 1&lt;/div&gt;`)[0];\n",
       "                popup_00f5605d6511947b3f0452ee3e7ed82a.setContent(html_8fb4d3ff38a7743f29f5379f7b8c62d2);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_4ca0e68d32d094c2305cfc3d0dd05067.bindPopup(popup_00f5605d6511947b3f0452ee3e7ed82a)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_8a6f0608c389d91bac82d9abb095a0ff = L.marker(\n",
       "                [48.35651560314171, -4.707264672124777],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_92e47d86837a11deacf8ba4b73baf4ff = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_8a6f0608c389d91bac82d9abb095a0ff.setIcon(icon_92e47d86837a11deacf8ba4b73baf4ff);\n",
       "        \n",
       "    \n",
       "        var popup_7bda0a83dd7f4db07c2a680b45571d09 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_08e26bb3479feeaec223fac031255029 = $(`&lt;div id=&quot;html_08e26bb3479feeaec223fac031255029&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Predicted 2&lt;/div&gt;`)[0];\n",
       "                popup_7bda0a83dd7f4db07c2a680b45571d09.setContent(html_08e26bb3479feeaec223fac031255029);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_8a6f0608c389d91bac82d9abb095a0ff.bindPopup(popup_7bda0a83dd7f4db07c2a680b45571d09)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_5cf3ace3272794ca4f122973172fdd96 = L.marker(\n",
       "                [48.322231634056045, -4.636478854667414],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_70697fe0465b7a5492c2fda38131da5a = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_5cf3ace3272794ca4f122973172fdd96.setIcon(icon_70697fe0465b7a5492c2fda38131da5a);\n",
       "        \n",
       "    \n",
       "        var popup_1542247c72849f486e45cd64bb240b7d = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_50768fd007f3bf1fc39d9e6ac890c47a = $(`&lt;div id=&quot;html_50768fd007f3bf1fc39d9e6ac890c47a&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Predicted 3&lt;/div&gt;`)[0];\n",
       "                popup_1542247c72849f486e45cd64bb240b7d.setContent(html_50768fd007f3bf1fc39d9e6ac890c47a);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_5cf3ace3272794ca4f122973172fdd96.bindPopup(popup_1542247c72849f486e45cd64bb240b7d)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_9010b21da16456258b06247474263cc4 = L.marker(\n",
       "                [48.351245354047826, -4.744884957883525],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_197ba194806afa155a6923bb251cf5f3 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_9010b21da16456258b06247474263cc4.setIcon(icon_197ba194806afa155a6923bb251cf5f3);\n",
       "        \n",
       "    \n",
       "        var popup_1963d5476ae9db5fb146ba920f5a5c93 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_b0df81b871d78a77ab3f98703ee02423 = $(`&lt;div id=&quot;html_b0df81b871d78a77ab3f98703ee02423&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Predicted 4&lt;/div&gt;`)[0];\n",
       "                popup_1963d5476ae9db5fb146ba920f5a5c93.setContent(html_b0df81b871d78a77ab3f98703ee02423);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_9010b21da16456258b06247474263cc4.bindPopup(popup_1963d5476ae9db5fb146ba920f5a5c93)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_d3ee9692764b0be0d364d283d20447e8 = L.marker(\n",
       "                [48.33407765219625, -4.713497991997767],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_fda56eb084744d66cac2927e31c24c54 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_d3ee9692764b0be0d364d283d20447e8.setIcon(icon_fda56eb084744d66cac2927e31c24c54);\n",
       "        \n",
       "    \n",
       "        var popup_bdff96658664974caaebdfdf773de4d2 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_43cdadbd226d93a621c81e63467eb164 = $(`&lt;div id=&quot;html_43cdadbd226d93a621c81e63467eb164&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Predicted 5&lt;/div&gt;`)[0];\n",
       "                popup_bdff96658664974caaebdfdf773de4d2.setContent(html_43cdadbd226d93a621c81e63467eb164);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_d3ee9692764b0be0d364d283d20447e8.bindPopup(popup_bdff96658664974caaebdfdf773de4d2)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_071eeba4ba26061c4d18d86e54587f8c = L.marker(\n",
       "                [48.29186996724628, -4.616932143315691],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_cf3758a55b1f9d3f59091c3a87d69943 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_071eeba4ba26061c4d18d86e54587f8c.setIcon(icon_cf3758a55b1f9d3f59091c3a87d69943);\n",
       "        \n",
       "    \n",
       "        var popup_1c036419ffee3a29eb2a2a0a4cb4f131 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_82341c814478e9d5c2262f09f33b264d = $(`&lt;div id=&quot;html_82341c814478e9d5c2262f09f33b264d&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Predicted 6&lt;/div&gt;`)[0];\n",
       "                popup_1c036419ffee3a29eb2a2a0a4cb4f131.setContent(html_82341c814478e9d5c2262f09f33b264d);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_071eeba4ba26061c4d18d86e54587f8c.bindPopup(popup_1c036419ffee3a29eb2a2a0a4cb4f131)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_f3c1990309b56e308b83bb08ca7c1e74 = L.marker(\n",
       "                [48.36564308381811, -4.841348507532868],\n",
       "                {}\n",
       "            ).addTo(map_862b2d00f8e404fff47bd42fb09b1d2d);\n",
       "        \n",
       "    \n",
       "            var icon_4c5a025fc2d90e23825f5df6403e0455 = L.AwesomeMarkers.icon(\n",
       "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;info-sign&quot;, &quot;iconColor&quot;: &quot;white&quot;, &quot;markerColor&quot;: &quot;red&quot;, &quot;prefix&quot;: &quot;glyphicon&quot;}\n",
       "            );\n",
       "            marker_f3c1990309b56e308b83bb08ca7c1e74.setIcon(icon_4c5a025fc2d90e23825f5df6403e0455);\n",
       "        \n",
       "    \n",
       "        var popup_5d47876881b9805815f46fe1872a91d4 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_67d43c408e53e74b15eb3539359d596c = $(`&lt;div id=&quot;html_67d43c408e53e74b15eb3539359d596c&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Predicted 7&lt;/div&gt;`)[0];\n",
       "                popup_5d47876881b9805815f46fe1872a91d4.setContent(html_67d43c408e53e74b15eb3539359d596c);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_f3c1990309b56e308b83bb08ca7c1e74.bindPopup(popup_5d47876881b9805815f46fe1872a91d4)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1c65ac7a050>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose vessel you want to track\n",
    "selected_mmsi = 227008170  # Replace this with the desired MMSI number\n",
    "\n",
    "#filter dataset for selected vessel\n",
    "selected_vessel_data = db[db['mmsi1'] == selected_mmsi]\n",
    "\n",
    "#feature and target selection\n",
    "selected_features = ['speed1', 'course1', 'heading1', 'ts1', 'speed2', 'course2', 'heading2', 'ts2', 'speed3', 'course3', 'heading3', 'ts3', 'speed4', 'course4', 'heading4', 'ts4', 'speed5', 'course5', 'heading5', 'ts5']\n",
    "selected_targets = ['lon1', 'lat1']\n",
    "\n",
    "x_selected = selected_vessel_data[selected_features]\n",
    "y_selected = selected_vessel_data[selected_targets]\n",
    "\n",
    "#split training and testing data\n",
    "X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(x_selected, y_selected, test_size=0.2, random_state=42)\n",
    "\n",
    "#create linear regression models\n",
    "lon_model_sel = LinearRegression()\n",
    "lat_model_sel = LinearRegression()\n",
    "\n",
    "#fit models\n",
    "lon_model_sel.fit(X_train_sel, y_train_sel['lon1'])\n",
    "lat_model_sel.fit(X_train_sel, y_train_sel['lat1'])\n",
    "\n",
    "#predict models\n",
    "lon_predictions_sel = lon_model_sel.predict(X_test_sel)\n",
    "lat_predictions_sel = lat_model_sel.predict(X_test_sel)\n",
    "\n",
    "#create the DataFrame for the predicted value\n",
    "lon_lat_p_sel = pd.DataFrame({\n",
    "    \"Longitude\": lon_predictions_sel,\n",
    "    \"Latitude\": lat_predictions_sel\n",
    "})\n",
    "\n",
    "#create thee GeoDataFrame\n",
    "geometry_sel = [Point(lon, lat) for lon, lat in zip(lon_predictions_sel, lat_predictions_sel)]\n",
    "geo_df_sel = gpd.GeoDataFrame({\n",
    "    'Longitude': lon_predictions_sel,\n",
    "    'Latitude': lat_predictions_sel\n",
    "}, geometry=geometry_sel)\n",
    "\n",
    "#create a map centered around the mean coordinates of the points\n",
    "mean_coords_sel = geo_df_sel['geometry'].unary_union.centroid\n",
    "m_sel = folium.Map(location=[mean_coords_sel.y, mean_coords_sel.x], zoom_start=6)\n",
    "\n",
    "#add the GeoDataFrame as your map markers\n",
    "for index, row in geo_df_sel.iterrows():\n",
    "    lat, lon = row['geometry'].y, row['geometry'].x\n",
    "\n",
    "    if index < len(lon_lat_p_sel) // 2:  #using half of the length to differentiate between original and predicted\n",
    "        color = 'blue'\n",
    "        label = f\"Original {index}\"  #add a label for original data\n",
    "    else:\n",
    "        color = 'red'\n",
    "        label = f\"Predicted {index - len(lon_lat_p_sel) // 2}\"  #subtract half length for predicted data\n",
    "\n",
    "    folium.Marker([lat, lon], icon=folium.Icon(color=color), popup=folium.Popup(label)).add_to(m_sel)\n",
    "\n",
    "\n",
    "#cisplay map\n",
    "m_sel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c6f22",
   "metadata": {},
   "source": [
    "Here we can see mixed results for this particular individual vessel. If we look at the markers, we can see that Marker 1 has acheived a valid predition ongoing from Marker 0 and going onto Marker 2. However, some Markers are inaccurate in the positioning, showing the ship as being on land, showing some inconsistency in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea4fbcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkE0lEQVR4nO3deVxUVf8H8M9l2BVQkE1AUHPNNc19Qy1zeULRR1Mft1wqrXApzTKXfhqVqWilpqWWWWhK2p4bJiUarplmpoECgpomuCIO5/fHbUYGZuDOMMNsn/frNS+bO+fee+6da/P1LN8jCSEEiIiIiJyIi7UrQERERFTZGAARERGR02EARERERE6HARARERE5HQZARERE5HQYABEREZHTYQBERERETocBEBERETkdBkBERETkdBgAkU3av38//vvf/yI0NBTu7u4ICQnBoEGDkJqaatRx5s6dC0mSTKrDnj17IEkS9uzZY9L+SnXr1g3dunWz6DmUiIqKgiRJ2lfVqlXRtm1bfPzxx5Vy/nXr1kGSJGRkZGi3mXpvXn/9dWzdutVsddPIyMiAJElYt26dwTJTpkyBJEk4deqUwTKvvPIKJEnC4cOHzV5Hc1ByncXLaV4uLi4ICAhAnz59jP67qlTJZ+LWrVuYO3eu3r+n+p4pIg0GQGRz3nnnHXTs2BFZWVl46623sHPnTrz99tvIzs5Gp06d8O677yo+1rhx40z+H/FDDz2E1NRUPPTQQybtb486duyI1NRUpKaman88Ro0ahRUrVlilPsuXL8fy5cuN3s9SAZASY8eOBQCsWbNG7+dFRUX4+OOP0aJFC4d5tp577jmkpqYiJSUF8fHxOHbsGKKjo3HkyBGzn6vkM3Hr1i3MmzdPbwDUt29fpKamIjQ01Oz1IPvnau0KEBX3888/Y/LkyejTpw+++OILuLref0SfeOIJDBgwAHFxcWjZsiU6duxo8Di3bt2Ct7c3wsPDER4eblJdfH190a5dO5P2tVfVqlXTueaePXsiMjISixcvxjPPPKN3H7VajXv37sHDw8Ps9WncuLHZj2lpTZo0QZs2bbB+/Xq8/vrrOs8wAGzfvh1ZWVmYMWOGlWpofrVq1dI+Nx07dsQDDzyAHj16YPny5Vi9erVZz2XMMxEYGIjAwECznp8cB1uAyKbEx8dDkiSsWLGi1A+Hq6srli9fDkmS8MYbb2i3a7q5Dh8+jEGDBqF69eqoW7euzmfFFRQUYNq0aQgJCYG3tze6dOmCQ4cOISoqCqNHj9aW09cFNnr0aFStWhVnzpxBnz59ULVqVURERGDatGkoKCjQOc+8efPQtm1b+Pv7w9fXFw899BA+/PBDmLL+cP/+/REZGYmioqJSn7Vt21anJeHzzz9H27Zt4efnB29vb9SpUwdPPvmk0ecE5ICoQYMGOHfuHID7XR5vvfUW5s+fj9q1a8PDwwPJyckAgIMHD+Lxxx+Hv78/PD090bJlS2zatKnUcffv34+OHTvC09MTNWvWxMyZM1FYWFiqnL4usIKCArz22mto1KgRPD09ERAQgOjoaOzbtw8AIEkSbt68iY8++kjbNVP8GLm5uXjqqacQHh4Od3d31K5dG/PmzcO9e/d0znPhwgUMHjwYPj4+8PPzw5AhQ5Cbm6vovo0dOxa5ubn47rvvSn22du1aeHh4YPjw4QCA/Px8vPDCC6hduzbc3d0RFhaGyZMn4+bNmzr7lfe9FhUVYf78+WjQoAG8vLxQrVo1NGvWDEuXLtU5zp9//olhw4YhKCgIHh4eaNSoEd577z1F16WUJhjSPDeA3CLWvHlzeHp6wt/fHwMGDMDvv/+us99ff/2FJ554AjVr1oSHhweCg4PRo0cPHD16VFum+DORkZGhDXDmzZun/b41f48NdYEpqYsxf9dXrFiB5s2bo2rVqvDx8UHDhg3x8ssvm3r7qJKwBYhshlqtRnJyMlq3bm2w1SYiIgKtWrXC7t27oVaroVKptJ/FxsbiiSeewNNPP13qx6O4MWPGYOPGjZg+fTq6d++OkydPYsCAAcjPz1dUz8LCQjz++OMYO3Yspk2bhr179+L//u//4Ofnh9mzZ2vLZWRk4KmnnkKtWrUAyD/6zz33HLKzs3XKKfHkk08iJiYGu3fvRs+ePbXbT506hV9++QXLli0DAKSmpmLIkCEYMmQI5s6dC09PT5w7dw67d+826nzFr/XcuXOl/hW9bNky1K9fH2+//TZ8fX1Rr149JCcn47HHHkPbtm2xcuVK+Pn5ITExEUOGDMGtW7e0P0onT55Ejx49EBUVhXXr1sHb2xvLly/Hp59+Wm597t27h969eyMlJQWTJ09G9+7dce/ePezfvx/nz59Hhw4dkJqaiu7duyM6OhqvvvoqALk1D5CDnzZt2sDFxQWzZ89G3bp1kZqaivnz5yMjIwNr164FANy+fRs9e/bEhQsXEB8fj/r16+Obb77BkCFDFN23oUOHYsqUKVizZg3+85//aLf/888/2LZtGwYMGIDq1avj1q1b6Nq1K7KysvDyyy+jWbNmOHHiBGbPno3jx49j586dkCRJ0ff61ltvYe7cuZg1axa6dOmCwsJCnDp1CteuXdOWOXnyJDp06IBatWph0aJFCAkJwQ8//IDnn38ef//9N+bMmaPo+spz5swZANA+N/Hx8Xj55ZcxdOhQxMfH48qVK5g7dy7at2+PtLQ01KtXDwDQp08fqNVqvPXWW6hVqxb+/vtv7Nu3T+caigsNDcX333+Pxx57DGPHjsW4ceN0zquP0roAyv6uJyYmYuLEiXjuuefw9ttvw8XFBWfOnMHJkycrfB/JwgSRjcjNzRUAxBNPPFFmuSFDhggA4uLFi0IIIebMmSMAiNmzZ5cqq/lM48SJEwKAmDFjhk65zz77TAAQo0aN0m5LTk4WAERycrJ226hRowQAsWnTJp39+/TpIxo0aGCwzmq1WhQWForXXntNBAQEiKKiIu1nXbt2FV27di3zmgsLC0VwcLAYNmyYzvbp06cLd3d38ffffwshhHj77bcFAHHt2rUyj6dPZGSk6NOnjygsLBSFhYUiPT1de70vvviiEEKI9PR0AUDUrVtX3L17V2f/hg0bipYtW4rCwkKd7f369ROhoaFCrVYLIeTvz8vLS+Tm5mrL3Lt3TzRs2FAAEOnp6drtJe/Nxx9/LACI1atXl3ktVapU0fkuNZ566ilRtWpVce7cOZ3tmvt24sQJIYQQK1asEADEtm3bdMqNHz9eABBr164t8/xCyM+Km5ub9jkVQoh33nlHABA7duwQQggRHx8vXFxcRFpams6+mzdvFgDEt99+q1O/sr7Xfv36iRYtWpRZp169eonw8HCRl5ens/3ZZ58Vnp6e4urVq0KI+99zedepKffmm2+KwsJCcefOHXHo0CHx8MMPCwDim2++Ef/884/w8vISffr00dn3/PnzwsPDQ/tM//333wKASEhIKPOcJZ+Jy5cvCwBizpw5pcquXbtW55lSWhchlP9df/bZZ0W1atXKrDPZJnaBkd0R/3YhlezaGjhwYLn7/vjjjwCAwYMH62wfNGhQqS43QyRJ0vlXPQA0a9ZMp7kfgLa1xs/PDyqVCm5ubpg9ezauXLmCS5cuKTqXhqurK/73v/8hKSkJeXl5AOQWs/Xr1yMmJgYBAQEAgIcfflh7fZs2bUJ2drZR5/n222/h5uYGNzc31K5dG5s2bcJzzz2H+fPn65R7/PHH4ebmpn1/5swZnDp1Stutc+/ePe2rT58+yMnJwR9//AEASE5ORo8ePRAcHKzdX6VSKWpd+e677+Dp6Wlyl97XX3+N6Oho1KxZU6eOvXv3BnD/+UhOToaPjw8ef/xxnf2HDRum+Fxjx45FYWEh1q9fr922du1aREZGokePHtr6NGnSBC1atNCpT69evXS6X5V8r23atMGxY8cwceJE/PDDD6VaNO/cuYNdu3ZhwIAB8Pb2LvUd3blzB/v371d8fcXNmDEDbm5u8PT0RKtWrXD+/Hm8//772tlgt2/f1uleBuTW3O7du2PXrl0AAH9/f9StWxcLFy7E4sWLceTIEb1dvhWhtC4aSv6ut2nTBteuXcPQoUOxbds2/P3332atM1kOAyCyGTVq1IC3tzfS09PLLJeRkQFvb2/4+/vrbFcy0+PKlSsAoPPjC8gBhiaIKI+3tzc8PT11tnl4eODOnTva97/88gseffRRAMDq1avx888/Iy0tDa+88goAuYvFWE8++STu3LmDxMREAMAPP/yAnJwcjBkzRlumS5cu2Lp1K+7du4eRI0ciPDwcTZo0wWeffaboHJ06dUJaWhoOHjyIkydP4tq1a1i2bBnc3d11ypW81xcvXgQAvPDCC9oASvOaOHEiAGh/GK5cuYKQkJBS59a3raTLly+jZs2acHEx7X9dFy9exFdffVWqjg8++GCpOpZ8RpTWUaNz586oX7++tlvt119/xeHDhzFmzBht8H7x4kX8+uuvperj4+MDIYS2Pkq+15kzZ+Ltt9/G/v370bt3bwQEBKBHjx44ePCg9pru3buHd955p9T5+vTpo3P9xoqLi0NaWhoOHTqEs2fPIicnBxMmTNCeF9D/97NmzZrazyVJwq5du9CrVy+89dZbeOihhxAYGIjnn38e169fN6leJSmti4aSv+sjRozAmjVrcO7cOQwcOBBBQUFo27YtduzYYZY6k+VwDBDZDJVKhejoaHz//ffIysrSOw4oKysLhw4dQu/evXXG/wClW4T00QQ5Fy9eRFhYmHb7vXv3Sv3PryISExPh5uaGr7/+Wud/oBWZmt24cWO0adMGa9euxVNPPYW1a9eiZs2a2kBLIyYmBjExMSgoKMD+/fsRHx+PYcOGISoqCu3bty/zHH5+fmjdunW5dSl5r2vUqAFA/hGOjY3Vu0+DBg0AyN+BvsHESgYYBwYG4qeffkJRUZFJQVCNGjXQrFkzLFiwQO/nNWvW1Nbxl19+MamOxT355JN46aWX8Msvv+DTTz+Fi4uLTutDjRo14OXlZXDKvOa+AuV/r66urpg6dSqmTp2Ka9euYefOnXj55ZfRq1cvZGZmonr16lCpVBgxYgQmTZqk93y1a9c26vo0wsPDDT43mr9zOTk5pT67cOGCzjVGRkbiww8/BACcPn0amzZtwty5c3H37l2sXLnSpLqZWhdjjBkzBmPGjMHNmzexd+9ezJkzB/369cPp06cRGRlZoTqT5bAFiGzKzJkzIYTAxIkToVardT5Tq9V45plnIITAzJkzTTp+ly5dAAAbN27U2b558+ZSs4AqQpIkuLq66gRpt2/f1ukOMcWYMWNw4MAB/PTTT/jqq68watSoUoGghoeHB7p27Yo333wTACySk0WjQYMGqFevHo4dO4bWrVvrffn4+AAAoqOjsWvXLm2rESB/tyW/E3169+6NO3fulJugz8PDQ28rW79+/fDbb7+hbt26euuoCYCio6Nx/fp1fPnllzr7KxmoXdyoUaPg6uqK999/Hxs2bECPHj10fhD79euHs2fPIiAgQG99oqKi9F5bed9rtWrVMGjQIEyaNAlXr17VtppqcvM0a9ZM7/mUtoIao3379vDy8sInn3yisz0rKwu7d+/WdgeWVL9+fcyaNQtNmzYtM2GkJv2CklZVU+uiVJUqVdC7d2+88soruHv3Lk6cOFGh45FlsQWIbErHjh2RkJCAyZMno1OnTnj22WdRq1YtnD9/Hu+99x4OHDiAhIQEdOjQwaTjP/jggxg6dCgWLVoElUqF7t2748SJE1i0aBH8/PxM7lopqW/fvli8eDGGDRuGCRMm4MqVK3j77bcrnCtn6NChmDp1KoYOHYqCgoJSYxlmz56NrKws9OjRA+Hh4bh27RqWLl0KNzc3dO3atULnLs/777+P3r17o1evXhg9ejTCwsJw9epV/P777zh8+DA+//xzAMCsWbPw5Zdfonv37pg9eza8vb3x3nvvlTlzT2Po0KFYu3Ytnn76afzxxx+Ijo5GUVERDhw4gEaNGuGJJ54AADRt2hR79uzBV199hdDQUPj4+KBBgwZ47bXXsGPHDnTo0AHPP/88GjRogDt37iAjIwPffvstVq5cifDwcIwcORJLlizByJEjsWDBAtSrVw/ffvstfvjhB6PuSUhICPr06YO1a9dCCKFNkqgxefJkbNmyBV26dMGUKVPQrFkzFBUV4fz589i+fTumTZuGtm3bKvpe//Of/6BJkyZo3bo1AgMDce7cOSQkJCAyMlI7s2np0qXo1KkTOnfujGeeeQZRUVG4fv06zpw5g6+++srk2YJlqVatGl599VW8/PLLGDlyJIYOHYorV65g3rx58PT01M48+/XXX/Hss8/iv//9L+rVqwd3d3fs3r0bv/76K1566SWDx/fx8UFkZCS2bduGHj16wN/fHzVq1NAbPCqtizHGjx8PLy8vdOzYEaGhocjNzUV8fDz8/Py0Y7fIRll1CDaRAampqWLQoEEiODhYuLq6iqCgIBEbGyv27dtXqqxmptfly5cNflbcnTt3xNSpU0VQUJDw9PQU7dq1E6mpqcLPz09MmTJFW87QLLAqVaooOs+aNWtEgwYNhIeHh6hTp46Ij48XH374YbkzncozbNgwAUB07Nix1Gdff/216N27twgLCxPu7u4iKChI9OnTR6SkpJR73MjISNG3b98yy2hm/SxcuFDv58eOHRODBw8WQUFBws3NTYSEhIju3buLlStX6pT7+eefRbt27YSHh4cICQkRL774oli1apWie3P79m0xe/ZsUa9ePeHu7i4CAgJE9+7ddZ6No0ePio4dOwpvb28BoNSsoeeff17Url1buLm5CX9/f9GqVSvxyiuviBs3bmjLZWVliYEDB4qqVasKHx8fMXDgQLFv3z7Fs8A0tm3bJgAIf39/cefOnVKf37hxQ8yaNUs0aNBAuLu7Cz8/P9G0aVMxZcoU7Uw5Jd/rokWLRIcOHUSNGjWEu7u7qFWrlhg7dqzIyMjQOV96erp48sknRVhYmHBzcxOBgYGiQ4cOYv78+TpllFxnec9DcR988IFo1qyZ9hpjYmK0s+6EEOLixYti9OjRomHDhqJKlSqiatWqolmzZmLJkiXi3r172nL6nomdO3eKli1bCg8PD53ZnCVngSmtixDK/65/9NFHIjo6WgQHBwt3d3dRs2ZNMXjwYPHrr7+We0/IuiQhTMjKRuRg9u3bh44dO2LDhg1GzfQhIiL7xACInM6OHTuQmpqKVq1awcvLC8eOHcMbb7wBPz8//Prrr6VmfRARkePhGCByOr6+vti+fTsSEhJw/fp11KhRA71790Z8fDyDHyIiJ8EWICIiInI6nAZPRERETocBEBERETkdBkBERETkdDgIWo+ioiJcuHABPj4+ipZXICIiIusTQuD69euK1gxkAKTHhQsXEBERYe1qEBERkQkyMzP1ridZHAMgPTRrFmVmZsLX19fKtSEiIiIl8vPzERERof0dLwsDID003V6+vr4MgIiIiOyMkuErHARNRERETocBEBERETkdBkBERETkdDgGiIiInIparUZhYaG1q0Emcnd3L3eKuxIMgIiIyCkIIZCbm4tr165ZuypUAS4uLqhduzbc3d0rdBwGQERE5BQ0wU9QUBC8vb2Z6NYOaRIV5+TkoFatWhX6DhkAERGRw1Or1drgJyAgwNrVoQoIDAzEhQsXcO/ePbi5uZl8HA6CJiIih6cZ8+Pt7W3lmlBFabq+1Gp1hY7DAIiIiJwGu73sn7m+Q3aBERGR3VGrgZQUICcHCA0FOncGVCpr14rsCVuAiIjIriQlAVFRQHQ0MGyY/GdUlLyddGVkZECSJBw9elTxPuvWrUO1atWsXg9LYwBERER2IykJGDQIyMrS3Z6dLW931CAoMzMTY8eORc2aNeHu7o7IyEjExcXhypUrZe4XERGBnJwcNGnSRPG5hgwZgtOnT1e0yjaPARAREdkFtRqIiwOEKP2ZZtvkyXI5S9Zhzx7gs8/kPy15Lo2//voLrVu3xunTp/HZZ5/hzJkzWLlyJXbt2oX27dvj6tWreve7e/cuVCoVQkJC4OqqfMSLl5cXgoKCzFV9m8UAiIiI7EJKSumWn+KEADIz5XKWYK2ut0mTJsHd3R3bt29H165dUatWLfTu3Rs7d+5EdnY2XnnlFQBAVFQU5s+fj9GjR8PPzw/jx4/X2/X05Zdfol69evDy8kJ0dDQ++ugjSJKkTRBZsgts7ty5aNGiBdavX4+oqCj4+fnhiSeewPXr17Vlvv/+e3Tq1AnVqlVDQEAA+vXrh7Nnz1r2xlQQAyAiIrILOTnmLWcMa3W9Xb16FT/88AMmTpwILy8vnc9CQkIwfPhwbNy4EeLfJrCFCxeiSZMmOHToEF599dVSx8vIyMCgQYPQv39/HD16FE899ZQ2gCrL2bNnsXXrVnz99df4+uuv8eOPP+KNN97Qfn7z5k1MnToVaWlp2LVrF1xcXDBgwAAUFRVV8A5YDmeBERGRXQgNNW85pcrrepMkuestJsb8M9H+/PNPCCHQqFEjvZ83atQI//zzDy5fvgwA6N69O1544QXt5xkZGTrlV65ciQYNGmDhwoUAgAYNGuC3337DggULyqxHUVER1q1bBx8fHwDAiBEjsGvXLu1+AwcO1Cn/4YcfIigoCCdPnjRq/FFlYgsQERHZhc6dgfBwOeDQR5KAiAi5nDlZu+utLJqWH01unNatW5dZ/o8//sDDDz+ss61NmzblnicqKkob/ABAaGgoLl26pH1/9uxZDBs2DHXq1IGvry9q164NADh//ryyC7ECBkBERGQXVCpg6VL5v0sGQZr3CQnmb4WxZtfbAw88AEmScPLkSb2fnzp1CtWrV0eNGjUAAFWqVCnzeEKIUokEhb6mrRJKLjkhSZJO99Z//vMfXLlyBatXr8aBAwdw4MABAPJAbFvFAIiIiOxGbCyweTMQFqa7PTxc3h4ba/5zWqvrDQACAgLwyCOPYPny5bh9+7bOZ7m5udiwYQOGDBmiODtyw4YNkZaWprPt4MGDFarjlStX8Pvvv2PWrFno0aOHtlvO1jEAIiIiuxIbC2RkAMnJwKefyn+mp1sm+AGs1/Wm8e6776KgoAC9evXC3r17kZmZie+//x6PPPIIwsLCyh2/U9xTTz2FU6dOYcaMGTh9+jQ2bdqEdevW/Xsdpi0xUb16dQQEBGDVqlU4c+YMdu/ejalTp5p0rMrEAIiIiOyOSgV06wYMHSr/acllMKzV9aZRr149HDx4EHXr1sWQIUNQt25dTJgwAdHR0UhNTYW/v7/iY9WuXRubN29GUlISmjVrhhUrVmhngXl4eJhUPxcXFyQmJuLQoUNo0qQJpkyZoh1kbcskoaTzz8nk5+fDz88PeXl58PX1tXZ1iIiogu7cuYP09HTUrl0bnp6eJh0jKUmeDVZ8QHREhBz8WKr1qTIsWLAAK1euRGZmprWrokhZ36Uxv9+cBk9ERKRAbKw81d3eF2Fdvnw5Hn74YQQEBODnn3/GwoUL8eyzz1q7WpWOARAREZFCmq43e/bnn39i/vz5uHr1KmrVqoVp06Zh5syZ1q5WpWMARERE5ESWLFmCJUuWWLsaVsdB0EREROR0GAARERGR02EARERERE6HARARERE5HQZARERE5HQYABEREZHTYQBEREREmDt3Llq0aKF9P3r0aPTv37/S65GRkQFJknD06FGLnocBEBERkQ0bPXo0JEmCJElwc3NDnTp18MILL+DmzZsWPe/SpUu1C6WWp7KCFnNiIkQiIiKl1GqrrIXx2GOPYe3atSgsLERKSgrGjRuHmzdvYsWKFTrlCgsL4ebmZpZz+vn5meU4tootQEREREokJQFRUUB0NDBsmPxnVJS83cI8PDwQEhKCiIgIDBs2DMOHD8fWrVu13VZr1qxBnTp14OHhASEE8vLyMGHCBAQFBcHX1xfdu3fHsWPHdI75xhtvIDg4GD4+Phg7dizu3Lmj83nJLrCioiK8+eabeOCBB+Dh4YFatWphwYIFAORV5gGgZcuWkCQJ3YqtF7J27Vo0atQInp6eaNiwIZYvX65znl9++QUtW7aEp6cnWrdujSNHjpjxzhnGFiAiIqLyJCUBgwYBQuhuz86Wt2/eXKlLwnt5eaGwsBAAcObMGWzatAlbtmyB6t/WqL59+8Lf3x/ffvst/Pz88P7776NHjx44ffo0/P39sWnTJsyZMwfvvfceOnfujPXr12PZsmWoU6eOwXPOnDkTq1evxpIlS9CpUyfk5OTg1KlTAOQgpk2bNti5cycefPBBuLu7AwBWr16NOXPm4N1330XLli1x5MgRjB8/HlWqVMGoUaNw8+ZN9OvXD927d8cnn3yC9PR0xMXFWfju/UtQKXl5eQKAyMvLs3ZViIjIDG7fvi1Onjwpbt++bfzO9+4JER4uhBz+lH5JkhAREXI5Cxg1apSIiYnRvj9w4IAICAgQgwcPFnPmzBFubm7i0qVL2s937dolfH19xZ07d3SOU7duXfH+++8LIYRo3769ePrpp3U+b9u2rWjevLne8+bn5wsPDw+xevVqvXVMT08XAMSRI0d0tkdERIhPP/1UZ9v//d//ifbt2wshhHj//feFv7+/uHnzpvbzFStW6D2WRlnfpTG/3+wCIyIiKktKCpCVZfhzIYDMTLmchXz99deoWrUqPD090b59e3Tp0gXvvPMOACAyMhKBgYHasocOHcKNGzcQEBCAqlWral/p6ek4e/YsAOD3339H+/btdc5R8n1xv//+OwoKCtCjRw/Fdb58+TIyMzMxduxYnXrMnz9fpx7NmzeHt7e3onqYE7vAiIiIypKTY95yJoiOjsaKFSvg5uaGmjVr6gx0rlKlik7ZoqIihIaGYs+ePaWOU61aNZPO7+XlZfQ+RUVFAORusLZt2+p8pumqEyW7FCsRAyAiIqKyhIaat5wJqlSpggceeEBR2Yceegi5ublwdXVFVFSU3jKNGjXC/v37MXLkSO22/fv3GzxmvXr14OXlhV27dmHcuHGlPteM+VGr1dptwcHBCAsLw19//YXhw4frPW7jxo2xfv163L59WxtklVUPc2IXGBERUVk6dwbCwwFJ0v+5JAEREXI5G9CzZ0+0b98e/fv3xw8//ICMjAzs27cPs2bNwsGDBwEAcXFxWLNmDdasWYPTp09jzpw5OHHihMFjenp6YsaMGZg+fTo+/vhjnD17Fvv378eHH34IAAgKCoKXlxe+//57XLx4EXl5eQDk5Irx8fFYunQpTp8+jePHj2Pt2rVYvHgxAGDYsGFwcXHB2LFjcfLkSXz77bd4++23LXyHZAyAiIiIyqJSAUuXyv9dMgjSvE9IqJR8QEpIkoRvv/0WXbp0wZNPPon69evjiSeeQEZGBoKDgwEAQ4YMwezZszFjxgy0atUK586dwzPPPFPmcV999VVMmzYNs2fPRqNGjTBkyBBcunQJAODq6oply5bh/fffR82aNRETEwMAGDduHD744AOsW7cOTZs2RdeuXbFu3TrttPmqVaviq6++wsmTJ9GyZUu88sorePPNNy14d+6ThDU74GxUfn4+/Pz8kJeXB19fX2tXh4iIKujOnTtIT09H7dq14enpadpBkpKAuDjdAdEREXLwU4lT4J1dWd+lMb/fHANERESkRGwsEBNjlUzQZH4MgIiIiJRSqYBiWY7JfnEMEBERETkdBkBERETkdBgAERGR0+C8H/tnru+QARARETk8TebkW7duWbkmVFF3794FcD+btKk4CJqIiByeSqVCtWrVtHlrvL29IRlKbEg2q6ioCJcvX4a3tzdcXSsWwjAAIiIipxASEgIA2iCI7JOLiwtq1apV4QCWARARETkFSZIQGhqKoKAgFBYWWrs6ZCJ3d3e4uFR8BA8DICIicioqlarC40fI/nEQNBERETkdBkBERETkdBgAERERkdNhAEREREROhwEQEREROR0GQEREROR0GAARERGR02EARERERE6HARARERE5HQZARERE5HQYABEREZHTYQBERERETsdmAqD4+HhIkoTJkydrt128eBGjR49GzZo14e3tjcceewx//vlnucfasmULGjduDA8PDzRu3BhffPGFBWtORERE9sYmAqC0tDSsWrUKzZo1024TQqB///7466+/sG3bNhw5cgSRkZHo2bMnbt68afBYqampGDJkCEaMGIFjx45hxIgRGDx4MA4cOFAZl0JERER2QBJCCGtW4MaNG3jooYewfPlyzJ8/Hy1atEBCQgJOnz6NBg0a4LfffsODDz4IAFCr1QgKCsKbb76JcePG6T3ekCFDkJ+fj++++0677bHHHkP16tXx2WefKapTfn4+/Pz8kJeXB19f34pfJBEREVmcMb/fVm8BmjRpEvr27YuePXvqbC8oKAAAeHp6arepVCq4u7vjp59+Mni81NRUPProozrbevXqhX379hncp6CgAPn5+TovIiIiclxWDYASExNx+PBhxMfHl/qsYcOGiIyMxMyZM/HPP//g7t27eOONN5Cbm4ucnByDx8zNzUVwcLDOtuDgYOTm5hrcJz4+Hn5+ftpXRESE6RdFRERENs9qAVBmZibi4uLwySef6LTyaLi5uWHLli04ffo0/P394e3tjT179qB3795QqVRlHluSJJ33QohS24qbOXMm8vLytK/MzEzTLoqIiIjsgqu1Tnzo0CFcunQJrVq10m5Tq9XYu3cv3n33XRQUFKBVq1Y4evQo8vLycPfuXQQGBqJt27Zo3bq1weOGhISUau25dOlSqVah4jw8PODh4VHxiyIiIiK7YLUWoB49euD48eM4evSo9tW6dWsMHz4cR48e1Wnl8fPzQ2BgIP78808cPHgQMTExBo/bvn177NixQ2fb9u3b0aFDB4tdCxEREdkXq7UA+fj4oEmTJjrbqlSpgoCAAO32zz//HIGBgahVqxaOHz+OuLg49O/fX2eQ88iRIxEWFqYdRxQXF4cuXbrgzTffRExMDLZt24adO3eWOXCaiIiInIvVAiAlcnJyMHXqVFy8eBGhoaEYOXIkXn31VZ0y58+fh4vL/YasDh06IDExEbNmzcKrr76KunXrYuPGjWjbtm1lV5+IiIhslNXzANki5gEiIiKyP3aVB4iIiIiosjEAIiIiIqfDAIiIiIicDgMgIiIicjoMgIiIiMjpMAAiIiIip8MAiIiIiJwOAyAiIiJyOgyAiIiIyOkwACIiIiKnwwCIiIiInA4DICIiInI6DICIiIjI6TAAIiIiIqfDAIiIiIicDgMgIiIicjqu1q4AEVmeWg2kpAA5OUBoKNC5M6BSWbtWRETWwwCIyMElJQFxcUBW1v1t4eHA0qVAbKz16kVEZE3sAiNyYElJwKBBusEPAGRny9uTkqxTLyIia2MAROSg1Gq55UeI0p9ptk2eLJcjInI2DICIHFRKSumWn+KEADIz5XJERM6GARCRg8rJMW85IiJHwgCIyEGFhpq3HBGRI2EAROSgOneWZ3tJkv7PJQmIiJDLERE5GwZARA5KpZKnugOlgyDN+4QE5gMiIufEAIjIgcXGAps3A2FhutvDw+XtzANERM6KiRCJHFxsLBATw0zQRETFMQAicgIqFdCtm7VrQURkO9gFRkRERE6HARARERE5HQZARERE5HQYABEREZHTYQBERERETocBEBERETkdBkBERETkdBgAERERkdNhAEREREROhwEQEREROR0GQEREROR0GAARERGR02EARERERE6HARARERE5HQZARERE5HQYABEREZHTYQBERERETocBEBERETkdBkBERETkdBgAERERkdNhAEREREROhwEQEREROR0GQEREROR0GAARERGR02EARERERE6HARARERE5HQZARERE5HQYABEREZHTcbV2BYiIyM6p1UBKCpCTA4SGAp07AyqVtWtFVCYGQEREZLqkJCAuDsjKur8tPBxYuhSIjbVevYjKwS4wIiIyTVISMGiQbvADyO8HDpQ/J7JRDICIiMh4arXc8iOE4TKjRsnliGwQAyAiIjJeSkrplp+SbtwAhg+vnPoQGYkBEBERGS8nR1m5zz8H7t61bF2ITMAAiIiIjBcaqqxcURGwfLll60JkApsJgOLj4yFJEiZPnqzdduPGDTz77LMIDw+Hl5cXGjVqhBUrVpR5nHXr1kGSpFKvO3fuWPgKiIicSOfOQJUqysr++adl60JkApuYBp+WloZVq1ahWbNmOtunTJmC5ORkfPLJJ4iKisL27dsxceJE1KxZEzExMQaP5+vriz/++ENnm6enp0XqTkTklFQqoEMHYMeO8styIDTZIKu3AN24cQPDhw/H6tWrUb16dZ3PUlNTMWrUKHTr1g1RUVGYMGECmjdvjoMHD5Z5TEmSEBISovMiIiIzK/H/bIP++cey9SAygdUDoEmTJqFv377o2bNnqc86deqEL7/8EtnZ2RBCIDk5GadPn0avXr3KPOaNGzcQGRmJ8PBw9OvXD0eOHCmzfEFBAfLz83VeREQVoVYDe/YAn30m/+mQjSCZmeYtR1SJrNoFlpiYiMOHDyMtLU3v58uWLcP48eMRHh4OV1dXuLi44IMPPkCnTp0MHrNhw4ZYt24dmjZtivz8fCxduhQdO3bEsWPHUK9ePb37xMfHY968eWa5JiJyTsVXg/jzT2D1aidIjnz5snnLEVUiqwVAmZmZiIuLw/bt2w2Oz1m2bBn279+PL7/8EpGRkdi7dy8mTpyI0NBQvS1GANCuXTu0a9dO+75jx4546KGH8M4772DZsmV695k5cyamTp2qfZ+fn4+IiIgKXB0RORN9q0GUlJ0tJ03evNmBgqDbt81bjqgSSUKUlcbTcrZu3YoBAwZAVWzBPLVaDUmS4OLigry8PFSvXh1ffPEF+vbtqy0zbtw4ZGVl4fvvv1d8rvHjxyMrKwvfffedovL5+fnw8/NDXl4efH19lV8UETkdzWoQSv9P6ucntwT98w8QGAiEhdnx2qEPPgicPFl+OXd3oKDA8vUhp2fM77fVWoB69OiB48eP62wbM2YMGjZsiBkzZkCtVqOwsBAuLrrDlFQqFYqKihSfRwiBo0ePomnTpmapNxGRhpLVIErKywNGj9bdFhgoJ0yOibGzYKh2bWUB0N27clboqlUtXycihawWAPn4+KBJkyY626pUqYKAgADt9q5du+LFF1+El5cXIiMj8eOPP+Ljjz/G4sWLtfuMHDkSYWFhiI+PBwDMmzcP7dq1Q7169ZCfn49ly5bh6NGjeO+99yrv4ojIKShZDUKJy5eBhAT5ZVdjhWrVUl52yBDgm28sVxciI9lEHiBDEhMTMXPmTAwfPhxXr15FZGQkFixYgKefflpb5vz58zqtRNeuXcOECROQm5sLPz8/tGzZEnv37kWbNm2scQlE5MCUrgZhjKws48YKFR98HRpayS1I9esrL5uSYrl6EJnAamOAbBnHABGREnv2ANHRljl21arA1q1At26GAxp9g69r1AD+979K6k67exfw8FBW1tOTg6HJ4oz5/bZ6HiAiInvVubPcZSVJ5j/2jRtAz55ASIi8nmhJmsHXJbvg/v5b7kqLjgaiouRyFuPurnw5DH9/C1aEyHgMgIiITKRSyeN1AMsEQYAc0AweLAcz/fsDixbJDSlKBl9nZQEDBwKvvWbBRIydOysrV2KpIyJrYwBERKSQvuzOsbHyeJ2wMN2yYWGAOXvQz50Dtm0DXngB8PY2bvD1nDlyl9rs2RYIhFwU/owcPmzmExNVDMcA6cExQERUkr7xNsVnbOkbjLxtm3E5giqDiwvw0ktA9+7ApUtmGDitNBcQANy6BXh5mXgi01h1kDhVOmN+vxkA6cEAiIiKM5TsUNPtVdaMLSVZoq2tQlPvIyKUX9zIkcBHH5lwEtOUF7SS42EAVEEMgIhIQ62Wx98Y+o2XJPlHNT3dcMuCphUiO1vO+RMQILe+zJkD3LxpsaobRZJMXKajZ09g1y5lZV1cKm1V2PIydDduLCenvnpVd7H6NWvkOI2tRPaJAVAFMQAiIg2lU92Tk+Up68ZISpIHKduK8HAgI8PIH//vvwd691ZevhJ+csoLWpXYsoWtRPaoUqbBnz17FrNmzcLQoUNx6dIlAMD333+PEydOmHpIIiKbozTZoSlJEWNj5R9apal0LC0rC5g3z8idHnnEInWpCHNk6B440MIpBMjqTAqAfvzxRzRt2hQHDhxAUlISbty4AQD49ddfMWfOHLNWkIjImkJDzVuupNhYYMwY0/a1hP/7P+A//zFiBxvsK5o2zTzHmTCh0nrsyApMCoBeeuklzJ8/Hzt27IC7u7t2e3R0NFJTU81WOSIiaysv2aEkyeOAlabD0afY8oY24euvgerVgVdflYf32GoQoElLsH49MHEi8Pjj8iQzc824v3KFK3g4MpMCoOPHj2PAgAGltgcGBuLKlSsVrhQRka0oK9mh5n1CQsUaQry85KUrbMm1a8D8+fIY5+Bg2+kOuntXDhgffljuOoyOlgctr1gBfPUVcOeOec9nifXeyDaYFABVq1YNOXqeiiNHjiCsZDYwIiI7ZyjZYXi4iTOn9Ni61faCII0rV8wzJkYAwJkzRu2jaeVZu1ZeFsTDQ+7iOniwclqmTO3aJNtn0iyw6dOnIzU1FZ9//jnq16+Pw4cP4+LFixg5ciRGjhxp9+OAOAuMyPGYIyFeZSTVu30bePFF4M8/gXr1gIUL5SW3vvsOmDoVOH9enr5tDQZniRmxDsg9F1e4qgv1fnb3rtzalpQEnDolpwgo1F+0UlStKreE2eAwJzLA4tPgCwsLMXr0aCQmJkIIAVdXV6jVagwbNgzr1q2Dys6fFgZARI7F0RLiqdXy+l5vvy0nV65Meqf7h4UBFy4o2r8IwIDHBbKygOvX5bVU1WrgxAmgqMjcta2YuXOB+vWZQdqeVFoeoLNnz+LIkSMoKipCy5YtUa9ePVMPZVMYABE5jopkcbZ1xRMs7tolrxr/76Rci/HxATw95cDr3j3A1RWIqnIZxy8FQUk7UBEAFWw//Zynp+54osBA4N13gaAgLqthy5gIsYIYABE5BnNkcbYnmvEyu3fLXWVnzgD791fSuSEpGlSqBuBqBwGQEjVqAMuXA//9r7VrQhoWCYCmTp2quAKLbW1Op5EYABE5BktmcbYXd+8C48cDGzdaduyQ0gDIXlqAjPHii8Bbb1m7FgQY9/vtqvSgR44c0Xl/6NAhqNVqNGjQAABw+vRpqFQqtGrVyoQqExGZnzmzOGtaV/bskd936ya/bL3lyN1dXn909Wq5teKHH+TVK8h8Fi4E2rSRu1rJfigOgJKTk7X/vXjxYvj4+OCjjz5C9erVAQD//PMPxowZg84VyQZGRGRG5srinJQkZwUunuZs/nx5UdNVq8ofQ1QZs8fKYmsr0rtAjSLYeORopPHj5Ra2sDCODbIXJo0BCgsLw/bt2/Hggw/qbP/tt9/w6KOP4oLC2QC2il1gRI5BMwYoO1v/GpxKxgApWbC0rIUzrTUDTRN0ffEFsGyZ5c6jPZ/CLjAA6IOt+A42mvTIDOx5hqG9s/hiqPn5+bh48WKp7ZcuXcL169dNOSQRkdlVNIvz3btyy0954uLkgEPTTfbZZ/Kfn38ud4uUbHnJypKDqtdes0wyv6QkOfCLjq6c4AeQx/YotRhmWqzLRmVny9+7rWTPJv1MCoAGDBiAMWPGYPPmzcjKykJWVhY2b96MsWPHIpYhLxHZEFOzOCclybN8lKzuk5UFLFhwP+gYNkz+c+hQ/S1PGnPmAJGRpv9Qlgy41Or70/4ru7vrFygf/xmFDMtVxAZovvPJk213HTUysQvs1q1beOGFF7BmzRoU/pum09XVFWPHjsXChQtRpUoVs1e0MrELjMjxGDMOR0m3lzlJkvH5iPR1rYWFAXl5ls8FpI838nAD1RTlAnKkqfDlceQZhrao0vIA3bx5E2fPnoUQAg888IDdBz4aDICInJdaLbfKZGdX7nkDA+Vgxt1dty76gjZDyR2tzZmnwhvy6adySyBVDotMg9enSpUqaNasWUUOQURkUzSZlSvb5ctyt9zKlXJLkL4WHn9/4LnngA8/tL3gh/TjYqq2y6QAKDo6GlIZi9/t3r3b5AoREVmT0txBlnD5styy88ILcm6Zkq5eBebNq/x6kX6SZDgQ1cwwZGYY22XSIOgWLVqgefPm2lfjxo1x9+5dHD58GE2bNjV3HYmILE4zoPjkSeX7+PrKC2aa26JF5j+mLZEAuOKuWY4VGKj7vmpVsxxWkRdekAMdU2YYkvWZ1AK0ZMkSvdvnzp2LG9YYfUdEVAGmJAqsUUPuKktJMW9dhLDf7q3bcEMVFJZbTgIwDW/iTbxaofOFhQF//QXs26c7TmrmTP0taMX5+ABPPQUkJup+7z4+wLRpQOPGwJNP6h9Q7uMDrFsnd1W2a6c/z1NCAvMA2TqzLoZ65swZtGnTBlevXjXXIa2Cg6CJnIepA4o1yQ8/+0ye9u7sWrYEVp9oh1Z3Dygq/zeqIRD/lNquya49fTpw9mzZxygrAeXdu3JL2qpVQH6+PH6qZUugXj2ge/f7y5iUNTtQrZYXlv3oIyAjQ05zMGqUvH/xlh1rZ/qm+6y2Gvz69esxY8YMZoImIrtQ3mrx+pRc/kLpgquOzMUFKCoy31R4TWDz+OPAV1+V/tzTE9iwgS0sVJrFZ4GVTHYohEBOTg4OHjyIV1+tWJMmEVFlSUlRFvz8739yoKRvAdTOneUuD0PLbTiDon/TQN+CHwSgKAAyRJLkBIIxMcCXXwK3b8tdUmlpQPXqwNSpwCOPVKyFhS02BJgYAPn6+urMAnNxcUGDBg3w2muv4dFHHzVb5YiILEnpjK8+fQznctEstzFoUNmzguyRKddTCMBDQbl7BrYLAWRmygFKt26Al5e8ir25WGttNrI9JgVA69atM3M1iIgqn7lWi9cst2FLK66bgynBnAQJUJDkUCqnncgS6QgMjffSrN1lbDZusm8mTYOvU6cOruhZIOfatWuoU6dOhStFRFQZNN1XhtKaSRIQEaEsl0tsrDxot+S0bHtl6nTyIijrSyrvx8fcCQTVajlA1RfUce0u52RSAJSRkQG1nqekoKAA2dZIoUpEZAJTVovXtwCpxr59cjJDR2BqRpPTeEBRORWE3lxAmgSCarX+e2yq8sZ7Fe96I+dgVBfYl19+qf3vH374AX5+ftr3arUau3btQlRUlNkqR0RkaYa6r/TlctE3fiQwEBg+XB60q/Tff888A6xYYZbqW5Vm9ldxHfEz8hFQ7kBoCcDzWIrFePH+tn/HHN2+DfTseb+sOcboKO1Ss2YmcKpcRk2Dd3GRG4wkSULJ3dzc3BAVFYVFixahX79+5q1lJeM0eCLnU97MICX5gmrUAP7+u/xzLVkCTJlS8Tpbi6Z1zNCSHXfgBg+Dw5zvS0E7dEGq9n1AAKBndIX2fBUZo6M0XQFXb7dvFpsGX/RvqF+7dm2kpaWhRo0apteSiMjKlE6HLmv8SHFKgh9A7mrRJOFTSpLkZH6aPLNK/ukqSXIrjbnHtRRvHWvXDpgwQTdw+Rv+CMOlco9TB3/pvL92TX85IXSnx5syZV1JuoKSa3dxurxjM2kMUHp6OoMfIrJrSUlybp/oaDmTc3S0/D4pqXRZpfmClFq82PjgB5ATMG7eLC8BoXSfqVPLXq/KWPPmAenpciCyZw9QUAB8+qlul5UKRQb3L65kubLuiSljdIqP10pJkVveAMPXfvs2sG2b/N9JSUBkpO7zERmp//kg+6S4BWjZsmWYMGECPD09sWzZsjLLPv/88xWuGBGRpSidDq1pAdiyxTr11Cg5HikmRrdl4u+/5S41Q2OYDK1XtWiRHCApTeIoScDq1fK4n3feud8aVdJNeCu6LqXlilM6RsdQvp8XXgDWrNHf1Xb1qvz9G+ray84GBg4sewkOsh+KxwDVrl0bBw8eREBAAGrXrm34gJKEv/76y+Dn9oBjgIjsT3lrOmk+CwoCRo823KKjmYW0eHHpoKKyvP020KIFcOmS8q6X8rprDH2uCQYB8yVxPIjmaIVfyy13CM3QGseMOraSMTqGAlzNIOvyEjyW93lAAHDxIrvDbJFFxgClp6fr/W8iImsrK7svYFyCQk1Xy3//a/56KlWzJtCjh3H7qFRlBwaGPo+NBTZuBCZOVD6GqTyuUNa/FwDjFs5WqcpPM6Ak3095gV55n1+5InetGfsdkW0xKRP0a6+9hhdeeAHe3rrNl7dv38bChQsxe/Zss1SOiKg8ZXVnDRxonTpVVEWSACppCcvOlgOJwEA5eePq1eYLfgAgD9UUlauJHLhArTh5oloNDB4MbNpkOEA193gtQ3bvvh8AcbC0fTJpNXiVSoWcnBwEBQXpbL9y5QqCgoL0Jkm0J+wCI7IPpqzmbss03W/p6ab9gJqzJawipmAhFmO6orLdsRPJMK4pxcUFmDQJqFNHDuLCwu4HHZ99Jg9atjQfH3ks0cmT8v0tPh6Ka4tZj8VXgxdC6CyGqnHs2DH4+/ubckgiIqNV1r/2K0PJzNPGtirYUkvYO4jD25iuaJpxd+w2OgDSDMIuThN0mHsJDUOuXzfcCpWVJd/zgQOBRo3krsdu3dgqZGuMCoCqV68OSZIgSRLq16+vEwSp1WrcuHEDTz/9tNkrSUTm5ShN9vactbdkHqDis7Y2b5bH5BQf71JWq4KScS+V6R7ccQKN0RQnyy0bgfNmOWdWlhwAbtxYfr6fyqKZPTh/vry22osvAq+8Yp9/1xyRUQFQQkIChBB48sknMW/ePJ2lMNzd3REVFYX27dubvZJEZD5ldZPYW5O9uf+1X7Wq3K1hzNRwU23YAAQHlw5Cp0/XPwVb8wOvLxuyLbaEfYnHFQVAWQg32zmFAKZNk/P9DB5c/myukjT/prfE937jBjBnjpx64IMPrDvInmRGBUCjRo0CIE+J79ChA9zc3CxSKSKyDKX5b+yFkuy+xvDykq9fpZLvR1k/oIamVCv90Q0OLj0r6/PP9Qc/GkLoz4Zsiy1hfyPQrOWUysyUlyTRt76bj4/cdWVIZbQY5efLwdmLLwJvvWX585FhJmWC7tq1qzb4uX37NvLz83VeRGR7lHSTTJ5s/mUTLEnJau7GuHxZbk3RdEOVlXE5PFzu4rhzR25xePbZ+38qUTJoUavlbq/y6MuG/Oefys5ZmS4i2KzljJGTI3+HGRly3qBPP5UzWJcV/FStavZqlGnhQvkZI+sxaRD0rVu3MH36dGzatAlX9KTTtPdZYESOqLxukuJLDdjTYpDlreYOAM8/r3yldk1gEhurm3FZM+lVX3LCyZPlP9VqICRE2XlKdt+lpCifil48eEpKkrtWbM0FKFivw4hyxtB8V5rcR5rZgmW5ccPs1SjXf/8L3LvHMUHWYlIA9OKLLyI5ORnLly/HyJEj8d577yE7Oxvvv/8+3njjDXPXkYjMQGk3iS12p5SnZLBSMtOxMa1BxQOT8pILlqQ0iAkM1F10EzDuvmvqqGnVs0Up6IxMhCMMWXq7GooAZCECKeis51Mz18UGx0hpbN1qv/mq7J1JXWBfffUVli9fjkGDBsHV1RWdO3fGrFmz8Prrr2PDhg3mriMRmYHSAcOVNY3Y3DTBytCh96cca8Y8KfnxkyQgIqJ0YGIMpUHM8OGl/9Wv9L4XD56U/rB7ecljTsINjDf29wfMnfKsCCrEYSkAqdTSqJr3k5GgOAmiMXJzdd/bclDPidPWY1IL0NWrV7Xrgfn6+uLqvxmgOnXqhGeeecZ8tSMisylvwLAmCV9FAgBbUtaYp5JK5uAxldIgJiam9DbN91NeQLN8+f06Kv1hv31bXl9s40Y5gCqeCVqTRBC434KWlGSe8SlfIBaDsBnrMAq+uN/H5AJADQltsR9fwPyj7ksul2HLQb01ut5IZlIAVKdOHWRkZCAyMhKNGzfGpk2b0KZNG3z11Vc6U+OJyHZoBgzrm91krgDAlhjT7VFytXVTKZmVZqiVqfj3Y2jfF1+8v3ApYNwPu2aKeFlZpjXjZZ56Svlxy9MW++GDGxAAivdEukBgOuQpby/BvNOhAktMLFMS/Pv7y2t8GTt1vqKUjhkjCxAmWLx4sVi6dKkQQojdu3cLLy8v4e7uLlxcXERCQoIph7QpeXl5AoDIy8uzdlWIzG7LFiHCw4WQ/zcvvyIi5O2O5NNPda/R0GvWLCHu3TPfebdsEUKS5Ffx82i2lXef9X0/gYFCbNpUuuy9e0L4+yu7Ts0rOfn+vsnJ8n1KThaioECIH34QokcP445X1ssVBeIeXESRgQJFgLgHF+GKArOds/g1Gvu9GPq78eKLQlSpov9cjRoJMXy4EC+9JMSiRUJ88okQgwcrr+ulSxV73kiXMb/fJq0FVtL58+dx8OBBBAYGYu3atVizZk3FIzMr4lpg5OgcJRN0WfbsAaKjyy+XnGz+WW/6kk1GRChvZTLm+3niCblrS6lPPwU8PIybGWeqyViMJZhWbrkpWIQETDXLOSMiDLdyKfleDN17tRrYtQtYv17uturUCXjuOcDdXX897t4F/PzkNAmG+PkB166ZeqWkjzG/32YJgDSOHTuGhx56yO6nwTMAIrJ/mqnP5Y15MnXhUSXnt3SQacpisLNnA6+9Zt56GJKE/hiAbeWW+wIxiMXWCp1L041bXjLPyg7+q1UD8vJKb2fwYxkWXwyViMjWWXvMk7FT6E1hyvTuygp+AMAbt8xarjgXF3lRVA2l47gq43sp7to1eVB2mzb3B57/8kvpcUpU+RgAEZHDKi9Joj0t+6GPLU/vBoCDaI1e2KGonIZKBUyZAjz2mNyNWVQEVK8OXL0qf4cREUD37nLLzb599tGNGxgotzSSbWEAVImcYdwFka0pK0mivbPl6d0AsAs98Ariyy23z6MHHosGevWSlwPRjKvp0aPs/ewpYznZHqMCoNhy/rl0jR2aBjnSCtxE9qayuz0qi7kXgzUHd3d5ADAA/Ihu+BsBCMAVnSnwGpoqf/nRVaiGVFYNiWRGZYL28/Mr8xUZGYmRI0daqq52y1A2Ws0K3ElJ1qkXEdm3shaDtQZfX2DDBuDWLWDSJKDnoyps7bXSYHnp35fqxWn2tQovOQYLT8lX7PXXXxcARFxcnHbb9evXxaRJk0RYWJjw9PQUDRs2FMuXLy/3WJs3bxaNGjUS7u7uolGjRiIpKcmoupgzD9C9e6XzSpTMQRERYd48JETkXPTlr7HGS5NjZ/JkORfPvXtC/g9Tk/cQGcmY32+T1gIzt7S0NKxatQrNmjXT2T5lyhR8//33+OSTT/D7779jypQpeO6557Btm+FplampqRgyZAhGjBiBY8eOYcSIERg8eDAOHDhg6cvQy5gVuImITBEbC2RkyDmNPv0U2L5dniVV2TTdcAkJcg6mqCjgl20OvAov2TWrB0A3btzA8OHDsXr1alSvXl3ns9TUVIwaNQrdunVDVFQUJkyYgObNm+PgwYMGj5eQkIBHHnkEM2fORMOGDTFz5kz06NEDCQkJFr4S/Rx5BW4ish3FF4N95BF52Qtry84GZiYEKSscpLAckZlYPQCaNGkS+vbti549e5b6rFOnTvjyyy+RnZ0NIQSSk5Nx+vRp9OrVy+DxUlNT8eijj+ps69WrF/bt22f2uivh6CtwE5Fteustee2wkrPdXFyAIUOAjz8GnnkGaN1azgxtCbYyMJtIH6tOg09MTMThw4eRlpam9/Nly5Zh/PjxCA8Ph6urK1xcXPDBBx+gU6dOBo+Zm5uL4OBgnW3BwcHIzc01uE9BQQEKCgq07/Pz8428EsOcbQVuIrIdb70FzJ8vryB/9ixw86bcPbZx4/3lM8LDgU8+kXPtDB4s59sxpyBcUlbwksJyRGZitRagzMxMxMXF4ZNPPoGnp6feMsuWLcP+/fvx5Zdf4tChQ1i0aBEmTpyInTt3lnlsqcR0CCFEqW3FxcfH68xmi4iIMP6CDChrloYjrsBNRNajVsvJAz/7TP5TrZanpU+eLI/JWbeu9Ppf2dly4JOXB6w0PGHLZDlgMzjZJrOuBWaMrVu3YsCAAVAV++VXq9WQJAkuLi7Iy8tD9erV8cUXX6Bv377aMuPGjUNWVha+//57vcetVasWpkyZgilTpmi3LVmyBAkJCTh37pzeffS1AEVERJh1LbCKLo5IRJZXPFmpZkjKpUv2kTyxrFxjMTFlrxkmSYC/P+Dpaf4FUl2gRgaiEIZsuKCMZnBLLcpGTsUu1gLr0aMHjh8/rrNtzJgxaNiwIWbMmAG1Wo3CwkK4lJjKoFKpUFR8AZgS2rdvjx07dugEQNu3b0eHDh0M7uPh4QEPS3WC/8uRs9ESOQJ9AURxtpy4VJNrrOQ/ZzW5xubOLX826pUr5Z/H1xcwdoRAEVSIw1JsxiAUQdINgtgMTtZk4Sn5RunatatOHqCuXbuKBx98UCQnJ4u//vpLrF27Vnh6eurkAhoxYoR46aWXtO9//vlnoVKpxBtvvCF+//138cYbbwhXV1exf/9+xfUwZx4gIrJ9W7bcz2FTVo4bSZLL2hIlucb8/c2T5yc8XIiXXjJt3wHYIs6jREUjImzvhpJdM+b326bXAktMTMTMmTMxfPhwXL16FZGRkViwYAGefvppbZnz58/rtBJ16NABiYmJmDVrFl599VXUrVsXGzduRNu2ba1xCUROxR7Xu1Or5Zaf8gYDCCE3WEyeLLfmlrwua127klxj5hrYnJUFXL9u2r5fIBbbEIPOSMHrz+agw0A7eUDIYVltDJAtM6YPkYhk9rre3Z498gBhYyQn664tZs1r/+wzYNiw8sv5+wP//FPxqekTJ8qzyiqi5P0jMhdjfr+tngeIiOyfPa93Z0oS0uL7JCUBAweWvvasLHl7Ra5dM6trwwZ5mMyGDfdnd2konTwVFyf/WdE1w+rVM31fSZInfzDtB9kCtgDpwRYgIuXU6vJnGNnyJJ+KtACp1UBwcNkDiAMCgIsXjb/2sgZlF29d0tz/8nKNpacD27aVPqaLC1DGvBIdERHAmTNA3bpld7vpowm8Nm+27RZBsm9sASKiSmPv691pkpUqaRkp2YKxZ0/5s6euXJHLGcNQi5pGVtb9ljVjco2VXDNsyRLlwY/mOO7u989njPDwYsGPvoRFRJWMARARVYi9r3dXVgBRnL4Z20oDG2MCIKWDsgF5QLZaLQcVmzcDYWG6n+sEHf8qvmZYiaT55Z7LmJYbSQICA+Us08nJcgtUbCzkqC0qSm52Gzbs/qqpttxPSg6JARARVYgjrHdnKIAoTl8wYQnltahplGxZK9m6oxN0GGDMdxITI/+pCdCU1O/yZfmeduv2b9Boz4PFyOHY9DR4IrJ9jrLeXclkpUoyQXfrJq+1VR5jZjwZ21JWvLymdUepzp3lAKW87M/Fvz+lAVqp+pXVtFVejgEbYI8pHqhsDICIqEI0XUiDBsm/YcV/3+wt0a+xAUS3bvIg5/IGQRtzTGNbyirSsqZSyb1QCxeWXW7p0vvfn7EBmrZ+xgwWs7E58vaa4oHKxi4wIqowY8agOBKVCli1quwyq1YZF/xpWtTKY44p5UlJwNtvG/68alVgyxbd78+YgEunfnY6WIy9do6LARARmYUpY1AcQWysHCToC/5KBg9KaFrUlMxKq0jLmpLB1tWq3R/7o2HMrDmd+tnhYLHyeu2A+wPRyf4wACIisyk+w0g78NUJxMYC587pBn8ZGaYHf5oWNUMtQRERFW9ZUzKWJyurdPoCJbPmAgL0BH9Km7YuXy6/TCWx9xQPVDaOASIiMgNjxw+Vp/ig7OxsOS4IDJRbmswxALciPVKaAK3kuJiAAOD554FXXtFTP5VKTjz03/+WfcJp0+QT2ED0bKe9dqQQAyAiIhtlSlCldLaS0p6mixflfIUlj1Vy1pyimVE1apR/QhsaCG2HvXZkBAZAREQOwpjZSuWlLwDkYGbKFMPHMjpAs7MmFUdJ8UD6cQwQEZEDMHa2kpKxPCUH91Z45pOdNakYs8wI2R8GQEREds7U2UqG0hcY+kE3dCzFS3uVN4XMBpeLd9YUD86Aq8HrwdXgicieKF3RXrOKfUl37wLLlwNnz8pBznvvKT+W0UkCNU1VgP6smTYaVTATtH0w5vebY4CIiOxcRYbW6AtglB5LE8uU/Ge0pqtMbyxjaApZeLjcn2SDwQ9g/ll+ZH0MgIiI7JypQ2sMBTBKBAUBo0ebuLSXSVPIiMyLARARkZ0zZbaSkkzQ+miOBVRwaS82qZCVcRA0EZGdM2W2krGrupc81qVLyvaxkRntRKUwACIicgDGzlYyJTApfiw7m9FOVAq7wIiIHIQxQ2uUBiZLlgDBwaWPxSSBZO84DV4PToMnR8cpvaRWA1FR5Qcw6emGnw07ndFODsyY3292gRE5maQk+YcvOhoYNkz+MyqqAtl9yS6ZI8sxkwSSPWMLkB5sASJHZWjaM//F7rz05QGKiDAuJQ9bFMlWGPP7zQBIDwZA5Ig0XR6GZv4o6fIg22OO4IMBDDkKZoImolLKm/Zcbt4WsjlGL0NhAFPykDPiGCAiJ1GR5RLI9hi7+rtNU7yaKpH5MAAichLM2+I4TF393SZxVD5ZCQMgIiehydtScsaPhiTJg1+Zt8X2GdOdadMcqhmL7A0DICInYY5pz2QbHKI706GascgeMQAiciLM2+IYHKI702GaschecRYYkZMxZrkEsk0OsQyFQzRjkT1jAETkhDjt2b5pujMHDZKDHX3LUNh8d6ZDNGORPWMXGBGRHbL77kyOyicrYwsQEZGdsuvuTIdoxiJ7xgCIiMiO2XV3pqYZS186a2MWIyMyAQMgIiKyHrtuxiJ7xgCIiIisy66bschecRA0EREROR0GQEREROR02AVGRETWp1ZzHBBVKgZARERkXUlJ+meCLV3KmWBkMewCIyIi6+GK8GQlDICIiMg6uCI8WREDICIisg6uCE9WxACIiIisgyvCkxUxACIiIuvgivBkRQyAiIjIOrgiPFkRAyAiIrIOzYrwQOkgiCvCk4UxACIiIuvRrAgfFqa7PTxc3s48QGQhTIRIRETWxRXhyQoYABERkfVxRXiqZOwCIyIiIqfDAIiIiIicDrvAiIiIqNKo1bYx3IsBEBEREVWKpCR5+bfiK6CEh8vZECp7wh+7wIiIiMjikpKAQYNKL/+WnS1vT0qq3PowACIiIiKLUqvllh8hSn+m2TZ5slyusjAAIiIiIotKSSnd8lOcEEBmplyusnAMEBER2RZbGSVLZpOTY95y5sAAiIiIbIctjZIlswkNNW85c2AXGBER2QZbGyVLZtO5sxzHllzzVkOSgIgIuVxlsZkAKD4+HpIkYfLkydptkiTpfS1cuNDgcdatW6d3nzt37lTCVRARkUlscZQsmY1KJTfiAaWDIM37hITK7em0iQAoLS0Nq1atQrNmzXS25+Tk6LzWrFkDSZIwcODAMo/n6+tbal9PT09LXgIREVWELY6SJbOKjQU2bwbCwnS3h4fL2yu7h9PqY4Bu3LiB4cOHY/Xq1Zg/f77OZyEhITrvt23bhujoaNSpU6fMY0qSVGpfIiKyYbY4SpbMLjYWiImxjTHuVm8BmjRpEvr27YuePXuWWe7ixYv45ptvMHbs2HKPeePGDURGRiI8PBz9+vXDkSNHzFVdIiKyBFscJUsWoVIB3boBQ4fKf1prgp9VW4ASExNx+PBhpKWllVv2o48+go+PD2LLaSNr2LAh1q1bh6ZNmyI/Px9Lly5Fx44dcezYMdSrV0/vPgUFBSgoKNC+z8/PN+5CiIioYjSjZLOz9Y8DkiT588ocJUsOzWotQJmZmYiLi8Mnn3yiaHzOmjVrMHz48HLLtmvXDv/73//QvHlzdO7cGZs2bUL9+vXxzjvvGNwnPj4efn5+2ldERITR10NERBVgi6NkyaFJQugLtS1v69atGDBgAFTFHma1Wg1JkuDi4oKCggLtZykpKejSpQuOHj2K5s2bG32u8ePHIysrC999953ez/W1AEVERCAvLw++vr5Gn4+IiEykLw9QRIQc/DAPEJUjPz8ffn5+in6/rdYF1qNHDxw/flxn25gxY9CwYUPMmDFDJzD68MMP0apVK5OCHyEEjh49iqZNmxos4+HhAQ8PD6OPTUREZmZLo2TJoVktAPLx8UGTJk10tlWpUgUBAQE62/Pz8/H5559j0aJFeo8zcuRIhIWFIT4+HgAwb948tGvXDvXq1UN+fj6WLVuGo0eP4r333rPcxRARkfloRskSWZDVp8GXJzExEUIIDB06VO/n58+fh4vL/aFM165dw4QJE5Cbmws/Pz+0bNkSe/fuRZs2bSqrykRERGTjrDYGyJYZ04dIREREtsGY32+r5wEiIiIiqmwMgIiIiMjpMAAiIiIip8MAiIiIiJwOAyAiIiJyOgyAiIiIyOkwACIiIiKnwwCIiIiInA4DICIiInI6DICIiIjI6TAAIiIiIqfDAIiIiIicDgMgIiIicjoMgIiIiMjpMAAiIiIip8MAiIiIiJwOAyAiIiJyOgyAiIiIyOkwACIiIiKnwwCIiIiInA4DICIiInI6DICIiIjI6TAAIiIiIqfDAIiIiIicjqu1K0BEZG5qNZCSAuTkAKGhQOfOgEpl7VoRkS1hAEREDiUpCYiLA7Ky7m8LDweWLgViY61XLyKyLewCIyKHkZQEDBqkG/wAQHa2vD0pyTr1IiLbwwCIiByCWi23/AhR+jPNtsmT5XJERAyAiMghpKSUbvkpTgggM1MuR0TEAIiIHEJOjnnLEZFjYwBERA4hNNS85YjIsTEAIiKH0LmzPNtLkvR/LklARIRcjoiIARAROQSVSp7qDpQOgjTvExKYD4iIZAyAiMhhxMYCmzcDYWG628PD5e3MA0REGkyESEQOJTYWiIlhJmgiKhsDICJyOCoV0K2btWtBRLaMXWBERETkdBgAERERkdNhAEREREROhwEQEREROR0GQEREROR0GAARERGR02EARERERE6HARARERE5HQZARERE5HQYABEREZHTYQBERERETocBEBERETkdLoZK5GDUaq6ETkRUHgZARA4kKQmIiwOysu5vCw8Hli4FYmOtVy8iIlvDLjAiB5GUBAwapBv8AEB2trw9Kck69SIiskUMgIgcgFott/wIUfozzbbJk+VyRETEAIjIIaSklG75KU4IIDNTLkdERAyAiBxCTo55yxEROToGQEQOIDTUvOWIiBwdAyAiB9C5szzbS5L0fy5JQESEXI6IiBgAETkElUqe6g6UDoI07xMSmA+IiEiDARCRg4iNBTZvBsLCdLeHh8vbmQeIiOg+JkIkciCxsUBMDDNBExGVhwEQkYNRqYBu3axdCyIi28YuMCIiInI6DICIiIjI6TAAIiIiIqdjMwFQfHw8JEnC5MmTtdskSdL7WrhwYZnH2rJlCxo3bgwPDw80btwYX3zxhYVrT0RERPbEJgKgtLQ0rFq1Cs2aNdPZnpOTo/Nas2YNJEnCwIEDDR4rNTUVQ4YMwYgRI3Ds2DGMGDECgwcPxoEDByx9GURERGQnJCH0rR9deW7cuIGHHnoIy5cvx/z589GiRQskJCToLdu/f39cv34du3btMni8IUOGID8/H999951222OPPYbq1avjs88+U1Sn/Px8+Pn5IS8vD76+vkZdDxEREVmHMb/fVm8BmjRpEvr27YuePXuWWe7ixYv45ptvMHbs2DLLpaam4tFHH9XZ1qtXL+zbt8/gPgUFBcjPz9d5ERERkeOyah6gxMREHD58GGlpaeWW/eijj+Dj44PYctLZ5ubmIjg4WGdbcHAwcnNzDe4THx+PefPmKas0ERER2T2rtQBlZmYiLi4On3zyCTw9Pcstv2bNGgwfPlxRWanEYkhCiFLbips5cyby8vK0r8zMzPIvgIiIiOyW1VqADh06hEuXLqFVq1babWq1Gnv37sW7776LgoICqP7N35+SkoI//vgDGzduLPe4ISEhpVp7Ll26VKpVqDgPDw94eHho32uGRbErjIiIyH5ofreVDG+22iDo69ev49y5czrbxowZg4YNG2LGjBlo0qSJdvvo0aPx22+/4eDBg+Ued8iQIbh+/Tq+/fZb7bbevXujWrVqigdBZ2VlISIiQuGVEBERkS3JzMxEeHh4mWWs1gLk4+OjE+QAQJUqVRAQEKCzPT8/H59//jkWLVqk9zgjR45EWFgY4uPjAQBxcXHo0qUL3nzzTcTExGDbtm3YuXMnfvrpJ8V1q1mzJjIzM+Hj44Pr168jIiICmZmZnBFWSfLz83nPKxHvd+XjPa9cvN+Vz1r3XAiB69evo2bNmuWWtfnFUBMTEyGEwNChQ/V+fv78ebi43B/K1KFDByQmJmLWrFl49dVXUbduXWzcuBFt27ZVfE4XFxdt5KgZO+Tr68u/OJWM97xy8X5XPt7zysX7Xfmscc/9/PwUlbN6HiBbx5xAlY/3vHLxflc+3vPKxftd+ezhnls9DxARERFRZWMAVA4PDw/MmTNHZ5YYWRbveeXi/a58vOeVi/e78tnDPWcXGBERETkdtgARERGR02EARERERE6HARARERE5HQZARERE5HQYABnwzTffoG3btvDy8kKNGjXKXYV+9OjRkCRJ59WuXbtKqq39M/Z+CyEwd+5c1KxZE15eXujWrRtOnDhRSbW1f1FRUaWe15deeqnMffiMm86U+81n3DwKCgrQokULSJKEo0ePllmWz7h5GHPPrfmcMwDSY8uWLRgxYgTGjBmDY8eO4eeff8awYcPK3e+xxx5DTk6O9lV8PTIyzJT7/dZbb2Hx4sV49913kZaWhpCQEDzyyCO4fv16JdXa/r322ms6z+usWbPK3YfPuOmMvd98xs1j+vTpipZF0OAzXnHG3HOrPueCdBQWFoqwsDDxwQcfGLXfqFGjRExMjGUq5cBMud9FRUUiJCREvPHGG9ptd+7cEX5+fmLlypWWqKbDiYyMFEuWLDFqHz7jpjP2fvMZN49vv/1WNGzYUJw4cUIAEEeOHCmzPJ/xijPmnlv7OWcLUAmHDx9GdnY2XFxc0LJlS4SGhqJ3796KmuT27NmDoKAg1K9fH+PHj8elS5cqocb2zZT7nZ6ejtzcXDz66KPabR4eHujatSv27dtXGdV2CG+++SYCAgLQokULLFiwAHfv3i13Hz7jpjPmfvMZr7iLFy9i/PjxWL9+Pby9vRXvx2fcdMbec2s/5wyASvjrr78AAHPnzsWsWbPw9ddfo3r16ujatSuuXr1qcL/evXtjw4YN2L17NxYtWoS0tDR0794dBQUFlVV1u2TK/c7NzQUABAcH62wPDg7WfkZli4uLQ2JiIpKTk/Hss88iISEBEydOLHMfPuOmM/Z+8xmvGCEERo8ejaeffhqtW7dWvB+fcdOZcs+t/pxbvI3JRsyZM0cAKPOVlpYmNmzYIACI999/X7vvnTt3RI0aNYxqkrtw4YJwc3MTW7ZsscTl2DxL3u+ff/5ZABAXLlzQ2T5u3DjRq1cvi16XLVN6z/XZvHmzACD+/vtvxefjM265+81nXD+l93zp0qWiQ4cO4t69e0IIIdLT0xV1gZXk7M+4EJa959Z+zl3NFknZuGeffRZPPPFEmWWioqK0A68aN26s3e7h4YE6derg/Pnzis8XGhqKyMhI/Pnnn6ZV2M5Z8n6HhIQAkP/1EBoaqt1+6dKlUv+ScCZK77k+mpkuZ86cQUBAgKLz8Rm33P3mM66f0ns+f/587N+/v9Q6VK1bt8bw4cPx0UcfKTqfsz/jgGXvubWfc6cJgGrUqIEaNWqUW65Vq1bw8PDAH3/8gU6dOgEACgsLkZGRgcjISMXnu3LlCjIzM3W+VGdiyftdu3ZthISEYMeOHWjZsiUA4O7du/jxxx/x5ptvmu8i7IzSe67PkSNHAMCo55XPuOXuN59x/ZTe82XLlmH+/Pna9xcuXECvXr2wceNGtG3bVvH5nP0ZByx7z63+nFu8jckOxcXFibCwMPHDDz+IU6dOibFjx4qgoCBx9epVbZkGDRqIpKQkIYQQ169fF9OmTRP79u0T6enpIjk5WbRv316EhYWJ/Px8a12G3TD2fgshxBtvvCH8/PxEUlKSOH78uBg6dKgIDQ3l/VZg3759YvHixeLIkSPir7/+Ehs3bhQ1a9YUjz/+uE45PuPmYcr9FoLPuDkZ6o7hM245Su65ENZ9zhkA6XH37l0xbdo0ERQUJHx8fETPnj3Fb7/9plMGgFi7dq0QQohbt26JRx99VAQGBgo3NzdRq1YtMWrUKHH+/Hkr1N7+GHu/hZCnT86ZM0eEhIQIDw8P0aVLF3H8+PFKrrl9OnTokGjbtq3w8/MTnp6eokGDBmLOnDni5s2bOuX4jJuHKfdbCD7j5mTox5jPuOUouedCWPc5l/6tEBEREZHT4DR4IiIicjoMgIiIiMjpMAAiIiIip8MAiIiIiJwOAyAiIiJyOgyAiIiIyOkwACIiIiKnwwCIiJxKRkYGJEnC0aNHLXJ8SZKwdetWixybiMyHARARVarRo0ejf//+Vjt/REQEcnJy0KRJEwDAnj17IEkSrl27ZrU6EVHlc5rFUImIAEClUmlXoSYi58UWICKyGT/++CPatGkDDw8PhIaG4qWXXsK9e/e0n3fr1g3PP/88pk+fDn9/f4SEhGDu3Lk6xzh16hQ6deoET09PNG7cGDt37tTplireBZaRkYHo6GgAQPXq1SFJEkaPHg0AiIqKQkJCgs6xW7RooXO+P//8E126dNGea8eOHaWuKTs7G0OGDEH16tUREBCAmJgYZGRkVPRWEVEFMQAiIpuQnZ2NPn364OGHH8axY8ewYsUKfPjhh5g/f75OuY8++ghVqlTBgQMH8NZbb+G1117TBh5FRUXo378/vL29ceDAAaxatQqvvPKKwXNGRERgy5YtAIA//vgDOTk5WLp0qaL6FhUVITY2FiqVCvv378fKlSsxY8YMnTK3bt1CdHQ0qlatir179+Knn35C1apV8dhjj+Hu3bvG3B4iMjN2gRGRTVi+fDkiIiLw7rvvQpIkNGzYEBcuXMCMGTMwe/ZsuLjI/15r1qwZ5syZAwCoV68e3n33XezatQuPPPIItm/fjrNnz2LPnj3abq4FCxbgkUce0XtOlUoFf39/AEBQUBCqVaumuL47d+7E77//joyMDISHhwMAXn/9dfTu3VtbJjExES4uLvjggw8gSRIAYO3atahWrRr27NmDRx991LibRERmwwCIiGzC77//jvbt22sDBQDo2LEjbty4gaysLNSqVQuAHAAVFxoaikuXLgGQW3EiIiJ0xvi0adPGYvWtVauWNvgBgPbt2+uUOXToEM6cOQMfHx+d7Xfu3MHZs2ctUi8iUoYBEBHZBCGETvCj2QZAZ7ubm5tOGUmSUFRUZPAYpnJxcdGeX6OwsLBU3UrWpbiioiK0atUKGzZsKFU2MDDQLPUkItMwACIim9C4cWNs2bJFJ4jZt28ffHx8EBYWpugYDRs2xPnz53Hx4kUEBwcDANLS0srcx93dHQCgVqt1tgcGBiInJ0f7Pj8/H+np6Tr1PX/+PC5cuICaNWsCAFJTU3WO8dBDD2Hjxo0ICgqCr6+vomsgosrBQdBEVOny8vJw9OhRndeECROQmZmJ5557DqdOncK2bdswZ84cTJ06VTv+pzyPPPII6tati1GjRuHXX3/Fzz//rB0EbahlKDIyEpIk4euvv8bly5dx48YNAED37t2xfv16pKSk4LfffsOoUaOgUqm0+/Xs2RMNGjTAyJEjcezYMaSkpJQacD18+HDUqFEDMTExSElJQXp6On788UfExcUhKyvLlFtHRGbCAIiIKt2ePXvQsmVLndecOXPw7bff4pdffkHz5s3x9NNPY+zYsZg1a5bi46pUKmzduhU3btzAww8/jHHjxmn39/T01LtPWFgY5s2bh5deegnBwcF49tlnAQAzZ85Ely5d0K9fP/Tp0wf9+/dH3bp1tfu5uLjgiy++QEFBAdq0aYNx48ZhwYIFOsf29vbG3r17UatWLcTGxqJRo0Z48skncfv2bbYIEVmZJPR1ZBMROYiff/4ZnTp1wpkzZ3QCGCJybgyAiMihfPHFF6hatSrq1auHM2fOIC4uDtWrV8dPP/1k7aoRkQ3hIGgicijXr1/H9OnTkZmZiRo1aqBnz55YtGiRtatFRDaGLUBERETkdDgImoiIiJwOAyAiIiJyOgyAiIiIyOkwACIiIiKnwwCIiIiInA4DICIiInI6DICIiIjI6TAAIiIiIqfDAIiIiIiczv8DMEJxpOVJ5hcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot\n",
    "plt.scatter(o_geo_df['Longitude'], o_geo_df['Latitude'], color=\"blue\", label='Original')\n",
    "plt.scatter(geo_df['Longitude'], geo_df['Latitude'], color=\"red\", label='Predicted')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Original vs Predicted Vessel Positions')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14b8b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude Standard Deviation: 0.2126427461989684\n",
      "Latitude Standard Deviation: 0.16018922933957724\n",
      "Original Longitude Standard Deviation: 0.0\n",
      "Original Latitude Standard Deviation: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate prediction errors\n",
    "lon_errors = y_test['lon1'] - lon_predictions\n",
    "lat_errors = y_test['lat1'] - lat_predictions\n",
    "\n",
    "o_lon_errors = y_test['lon1'] - original_lon1\n",
    "o_lat_errors = y_test['lat1'] - original_lat1\n",
    "\n",
    "# Calculate standard deviation of errors\n",
    "lon_std_dev = np.std(lon_errors)\n",
    "lat_std_dev = np.std(lat_errors)\n",
    "\n",
    "o_lon_std_dev = np.std(o_lon_errors)\n",
    "o_lat_std_dev = np.std(o_lat_errors)\n",
    "\n",
    "print(f\"Longitude Standard Deviation: {lon_std_dev}\")\n",
    "print(f\"Latitude Standard Deviation: {lat_std_dev}\")\n",
    "print(f\"Original Longitude Standard Deviation: {o_lon_std_dev}\")\n",
    "print(f\"Original Latitude Standard Deviation: {o_lat_std_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2967b78",
   "metadata": {},
   "source": [
    "This result indicates the following:\n",
    " - The longitude and latidude for the original shows the \"true value\".\n",
    " - On average, it is suggested from the data that the model has a degree of accuracy of 18.5% from the true longitude and 15.7% degrees from the true latitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ab822ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude MSE: 0.04526493503526796\n",
      "Latitude MSE: 0.02628314559210206\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "lon_mse = mean_squared_error(y_test['lon1'], lon_predictions)\n",
    "lat_mse = mean_squared_error(y_test['lat1'], lat_predictions)\n",
    "print(f\"Longitude MSE: {lon_mse}\")\n",
    "print(f\"Latitude MSE: {lat_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae21f08",
   "metadata": {},
   "source": [
    "The MSE (Mean Squared Error) results could indicate the following:\n",
    " - For both longitude and latitude values, the above results indicate that the model´s predicted values are relatively close to the original values, indicating quality and that the model is performing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efe7e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude RMSE: 0.22644512562002597\n",
      "Latitude RMSE: 0.0652141465574302\n"
     ]
    }
   ],
   "source": [
    "#RMSE evaluation\n",
    "#perform k-fold cross-validation\n",
    "lon_predictions_cv = cross_val_predict(lon_model_sel, x_selected, y_selected['lon1'], cv=5)\n",
    "lat_predictions_cv = cross_val_predict(lat_model_sel, x_selected, y_selected['lat1'], cv=5)\n",
    "\n",
    "lon_rmse = np.sqrt(mean_squared_error(y_selected['lon1'], lon_predictions_cv))\n",
    "lat_rmse = np.sqrt(mean_squared_error(y_selected['lat1'], lat_predictions_cv))\n",
    "\n",
    "print(f\"Longitude RMSE: {lon_rmse}\")\n",
    "print(f\"Latitude RMSE: {lat_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e25481",
   "metadata": {},
   "source": [
    "The fact that the RMSE results are relatively low for latitude and somewhat low for longitude could suggest that the model is performing somewhat well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38ce69d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude R-squared: -2.9300212311712586\n",
      "Latitude R-squared: -2.210264387248147\n"
     ]
    }
   ],
   "source": [
    "#R-squared evaluation\n",
    "lon_r2 = r2_score(y_selected['lon1'], lon_predictions_cv)\n",
    "lat_r2 = r2_score(y_selected['lat1'], lat_predictions_cv)\n",
    "\n",
    "print(f\"Longitude R-squared: {lon_r2}\")\n",
    "print(f\"Latitude R-squared: {lat_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7eeaa8",
   "metadata": {},
   "source": [
    "The above indicates that the model is not a good fit for the current data, the data could be being overfitted, underfitted or simply not capturing the underlying patterns assosiated with the data. This could indicate that there was a problem during feature selection, model selection or another preprocessing problem. This result only implies more that we should try other models and evaluate their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd813b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
